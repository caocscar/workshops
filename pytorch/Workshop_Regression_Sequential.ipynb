{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Workshop Regression Sequential",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/caocscar/workshops/blob/master/pytorch/Workshop_Regression_Sequential.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7G_TdHMkSL8q",
        "colab_type": "text"
      },
      "source": [
        "**Regression Problem**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWhz8RPhRfF1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "89b06b15-8e9a-48ae-c8e4-39335e948c06"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "print('Torch version', torch.__version__)\n",
        "print('Pandas version', pd.__version__)\n",
        "print('Numpy version', np.__version__)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Torch version 1.3.1\n",
            "Pandas version 0.25.3\n",
            "Numpy version 1.17.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d80zm5dOSsOr",
        "colab_type": "text"
      },
      "source": [
        "The following should say `cuda:0`. If it does not, we need to go to *Edit* -> *Notebook settings* and change it to a `GPU` from `None`. You only have to do this once per notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ga1yyVAfRgK3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "13c53a0d-69df-4b6c-c5a8-9311cd6de943"
      },
      "source": [
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2ehDuMJjdGF",
        "colab_type": "text"
      },
      "source": [
        "Read in dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3U_r7UGpRf-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.read_csv('https://raw.githubusercontent.com/greght/Workshop-Keras-DNN/master/ChallengeProblems/dataRegression_train.csv', header=None)\n",
        "df_test = pd.read_csv('https://raw.githubusercontent.com/greght/Workshop-Keras-DNN/master/ChallengeProblems/dataRegression_test.csv', header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DADwh9RXji1w",
        "colab_type": "text"
      },
      "source": [
        "Construct our x,y variables along with the training and validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EBgffu2RgG_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = df_train.iloc[:,0:2]\n",
        "y_train = df_train.iloc[:,2]\n",
        "x_test = df_test.iloc[:,0:2]\n",
        "y_test = df_test.iloc[:,2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03iB31pbgPtL",
        "colab_type": "text"
      },
      "source": [
        "Preprocess our data to go from a `pandas` DataFrame to a `numpy` array to a `torch` tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjq5O0XfRmPv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_tensor = torch.tensor(x_train.to_numpy(), device=device, dtype=torch.float, requires_grad=True)\n",
        "y_train_tensor = torch.tensor(y_train.to_numpy(), device=device, dtype=torch.float, requires_grad=True)\n",
        "x_test_tensor = torch.tensor(x_test.to_numpy(), device=device, dtype=torch.float, requires_grad=True)\n",
        "y_test_tensor = torch.tensor(y_test.to_numpy(), device=device, dtype=torch.float, requires_grad=True)\n",
        "y_train_tensor = y_train_tensor.view(-1,1)\n",
        "y_test_tensor = y_test_tensor.view(-1,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xab-wXwDjmpq",
        "colab_type": "text"
      },
      "source": [
        "Set up our model using the `nn.Sequential` function. We then have to transfer it to the GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RT7-GH0eRmS_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "9e54dc37-876c-4bd7-a339-5c2eeae6ca0a"
      },
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(x_train_tensor.shape[1],5),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(5,5),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(5,1),\n",
        ").to(device)\n",
        "print(model)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=2, out_features=5, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=5, out_features=5, bias=True)\n",
            "  (3): ReLU()\n",
            "  (4): Linear(in_features=5, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryc3EnW4RwqI",
        "colab_type": "text"
      },
      "source": [
        "`model.parameters()` contains the **weights** and **bias** (alternating) for each of the 3 layers\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-VGjPHeRmWH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "a40a1d11-8630-4ddb-8016-b24b3579ddb8"
      },
      "source": [
        "params = list(model.parameters())\n",
        "print(f'There are {len(params)} parameters')\n",
        "for param in params:\n",
        "    print(param)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 6 parameters\n",
            "Parameter containing:\n",
            "tensor([[ 0.2993, -0.7038],\n",
            "        [-0.2556, -0.2137],\n",
            "        [ 0.4313, -0.2261],\n",
            "        [ 0.6978, -0.4342],\n",
            "        [ 0.2998,  0.4698]], device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.3835, -0.0449,  0.3708, -0.5495,  0.0828], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.3304, -0.0695, -0.1616,  0.1920, -0.0792],\n",
            "        [-0.0019, -0.0333,  0.1520,  0.2004,  0.3427],\n",
            "        [ 0.4436,  0.4199,  0.1999,  0.1085,  0.0091],\n",
            "        [ 0.2067,  0.0822,  0.2345, -0.1940,  0.3547],\n",
            "        [ 0.3026, -0.1192, -0.0611, -0.0837,  0.4313]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.0255, -0.0129,  0.2609, -0.3787,  0.0815], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.2820,  0.1917,  0.1158,  0.2552, -0.3178]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.1014], device='cuda:0', requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJnryBGCj8da",
        "colab_type": "text"
      },
      "source": [
        "We define our *loss function*, *learning rate*, and our *optimizer*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSM7o32MRmZQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_fn = nn.MSELoss(reduction='mean') #default\n",
        "learning_rate = 0.1\n",
        "optimizer = optim.Adagrad(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7y80N-dmkVFK",
        "colab_type": "text"
      },
      "source": [
        "Here is our training loop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jInSwhL8RmcY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "9e907bea-7e95-4b86-d24e-9b09ba389e4a"
      },
      "source": [
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "    # training\n",
        "    output = model(x_train_tensor)\n",
        "    loss = loss_fn(output, y_train_tensor)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    # testing\n",
        "    yhat = model(x_test_tensor)\n",
        "    validation_loss = loss_fn(yhat, y_test_tensor)\n",
        "    # print intermediate results\n",
        "    if epoch % 10 == 9:\n",
        "        print(epoch, loss.item(), validation_loss.item())"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9 5.108928680419922 7.624905586242676\n",
            "19 4.459510326385498 6.413210391998291\n",
            "29 4.118618488311768 5.67863130569458\n",
            "39 3.918602228164673 5.210153102874756\n",
            "49 3.789799213409424 4.893531322479248\n",
            "59 3.6861917972564697 4.655496597290039\n",
            "69 3.5980217456817627 4.458011150360107\n",
            "79 3.5049703121185303 4.278006553649902\n",
            "89 3.4194657802581787 4.097975254058838\n",
            "99 3.344447374343872 3.9381158351898193\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDl8eHfleK_C",
        "colab_type": "text"
      },
      "source": [
        "We can generalize some of the code inside the `for` loop. We'll define a template for our `fit_model` function that contains `train` and `validate` functions. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amLbK4yBRmfg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit_model(model, loss_fn, optimizer):\n",
        "    def train(x,y):\n",
        "        yhat = model(x)\n",
        "        loss = loss_fn(yhat,y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        return loss.item()\n",
        "    \n",
        "    def validate(x,y):\n",
        "        yhat = model(x)\n",
        "        loss = loss_fn(yhat,y)\n",
        "        return loss.item()\n",
        "    \n",
        "    return train, validate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2NAjWtvkIa6",
        "colab_type": "text"
      },
      "source": [
        " We pass our model, loss function, and optimizer to `fit_model` to return our `train` and `validate` functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k49SNPv4Rmi3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, validate = fit_model(model, loss_fn, optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoY2RMROeg4A",
        "colab_type": "text"
      },
      "source": [
        "## Mini-batches\n",
        "\n",
        "From the documentation: `torch.nn` only supports mini-batches. The entire `torch.nn` package only supports inputs that are a mini-batch of samples, and not a single sample."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfkZGCz7RmmA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = TensorDataset(x_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(dataset=train_data, batch_size=10, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pU9J7-E9kgXi",
        "colab_type": "text"
      },
      "source": [
        "Here is our training loop with mini-batch processing. We have to move each mini-batch onto the GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yweeH2KERmpC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "22953558-9beb-4ee8-835c-16810df87893"
      },
      "source": [
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "    # training\n",
        "    losses = []\n",
        "    for i, (xbatch, ybatch) in enumerate(train_loader):\n",
        "        xbatch = xbatch.to(device)\n",
        "        ybatch = ybatch.to(device)\n",
        "        loss = train(xbatch, ybatch)\n",
        "        losses.append(loss)\n",
        "    training_loss = np.mean(losses)\n",
        "    # validation\n",
        "    validation_loss = validate(x_test_tensor, y_test_tensor)\n",
        "    if epoch%10 == 9:\n",
        "        print(epoch, training_loss, validation_loss)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9 3.277724266052246 3.5477635860443115\n",
            "19 3.102418693629178 3.2486870288848877\n",
            "29 2.9172640171918003 2.9883697032928467\n",
            "39 2.7863523851741445 2.6826000213623047\n",
            "49 2.543387673117898 2.3177974224090576\n",
            "59 2.4614998427304355 2.1546740531921387\n",
            "69 2.403803164308721 1.9900814294815063\n",
            "79 2.33422927422957 2.0553269386291504\n",
            "89 2.2794611291451887 1.8800286054611206\n",
            "99 2.237360813400962 1.7929385900497437\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMIPmGVBlISA",
        "colab_type": "text"
      },
      "source": [
        "We can view the current state of our model using the `state_dict` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXP_8gPQlHtL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "d62ad005-85a9-40f8-dab3-7609dbca405b"
      },
      "source": [
        "model.state_dict()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('0.weight', tensor([[-0.0169, -1.9129],\n",
              "                      [-0.2556, -0.2137],\n",
              "                      [ 0.4382,  0.3790],\n",
              "                      [ 1.9701,  0.1989],\n",
              "                      [ 0.1641,  0.9642]], device='cuda:0')),\n",
              "             ('0.bias',\n",
              "              tensor([ 0.6931, -0.0449,  0.7120, -1.1062,  0.2659], device='cuda:0')),\n",
              "             ('2.weight',\n",
              "              tensor([[-0.3304, -0.0695, -0.1616,  0.1920, -0.0792],\n",
              "                      [ 1.6074, -0.0333,  0.3871,  1.9815,  0.7275],\n",
              "                      [ 2.1149,  0.4199,  0.4397,  1.8962,  0.4107],\n",
              "                      [ 1.8056,  0.0822,  0.4862,  1.5626,  0.7789],\n",
              "                      [-0.4971, -0.1192,  0.5471, -1.6378,  0.7071]], device='cuda:0')),\n",
              "             ('2.bias',\n",
              "              tensor([ 0.0255,  0.3121,  0.5950, -0.0270,  0.1713], device='cuda:0')),\n",
              "             ('4.weight',\n",
              "              tensor([[-0.2820,  0.9930,  0.8562,  1.0883, -1.0211]], device='cuda:0')),\n",
              "             ('4.bias', tensor([0.3773], device='cuda:0'))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    }
  ]
}