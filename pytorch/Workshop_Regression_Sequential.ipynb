{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Workshop Regression Sequential",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/caocscar/workshops/blob/master/pytorch/Workshop_Regression_Sequential.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7G_TdHMkSL8q",
        "colab_type": "text"
      },
      "source": [
        "**Regression Problem**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWhz8RPhRfF1",
        "colab_type": "code",
        "outputId": "bf2047ad-22fa-448b-85db-59ba6fc62593",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "print('Torch version', torch.__version__)\n",
        "print('Pandas version', pd.__version__)\n",
        "print('Numpy version', np.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Torch version 1.3.1\n",
            "Pandas version 0.25.3\n",
            "Numpy version 1.17.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d80zm5dOSsOr",
        "colab_type": "text"
      },
      "source": [
        "The following should say `cuda:0`. If it does not, we need to go to *Edit* -> *Notebook settings* and change it to a `GPU` from `None`. You only have to do this once per notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ga1yyVAfRgK3",
        "colab_type": "code",
        "outputId": "f75e09ca-f93c-418d-9666-02eb75187fab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2ehDuMJjdGF",
        "colab_type": "text"
      },
      "source": [
        "Read in dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3U_r7UGpRf-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.read_csv('https://raw.githubusercontent.com/greght/Workshop-Keras-DNN/master/ChallengeProblems/dataRegression_train.csv', header=None)\n",
        "df_val = pd.read_csv('https://raw.githubusercontent.com/greght/Workshop-Keras-DNN/master/ChallengeProblems/dataRegression_test.csv', header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DADwh9RXji1w",
        "colab_type": "text"
      },
      "source": [
        "Construct our x,y variables along with the training and validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EBgffu2RgG_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = df_train.iloc[:,0:2]\n",
        "y_train = df_train.iloc[:,2]\n",
        "x_val = df_val.iloc[:,0:2]\n",
        "y_val = df_val.iloc[:,2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03iB31pbgPtL",
        "colab_type": "text"
      },
      "source": [
        "Preprocess our data to go from a `pandas` DataFrame to a `numpy` array to a `torch` tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjq5O0XfRmPv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_tensor = torch.tensor(x_train.to_numpy(), device=device, dtype=torch.float, requires_grad=True)\n",
        "y_train_tensor = torch.tensor(y_train.to_numpy(), device=device, dtype=torch.float, requires_grad=True)\n",
        "x_val_tensor = torch.tensor(x_val.to_numpy(), device=device, dtype=torch.float, requires_grad=True)\n",
        "y_val_tensor = torch.tensor(y_val.to_numpy(), device=device, dtype=torch.float, requires_grad=True)\n",
        "y_train_tensor = y_train_tensor.view(-1,1)\n",
        "y_val_tensor = y_val_tensor.view(-1,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xab-wXwDjmpq",
        "colab_type": "text"
      },
      "source": [
        "Set up our model using the `nn.Sequential` function. We then have to transfer it to the GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RT7-GH0eRmS_",
        "colab_type": "code",
        "outputId": "292d301d-f839-4427-dd7f-8f6ff4a4af92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(x_train_tensor.shape[1],5),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(5,5),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(5,1),\n",
        ").to(device)\n",
        "print(model)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=2, out_features=5, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=5, out_features=5, bias=True)\n",
            "  (3): ReLU()\n",
            "  (4): Linear(in_features=5, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryc3EnW4RwqI",
        "colab_type": "text"
      },
      "source": [
        "`model.parameters()` contains the **weights** and **bias** (alternating) for each of the 3 layers\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-VGjPHeRmWH",
        "colab_type": "code",
        "outputId": "4a2d7ac0-2d25-4552-c9f0-e871792f163d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "source": [
        "params = list(model.parameters())\n",
        "print(f'There are {len(params)} parameters')\n",
        "for param in params:\n",
        "    print(param)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 6 parameters\n",
            "Parameter containing:\n",
            "tensor([[-0.1215, -0.3991],\n",
            "        [ 0.2788,  0.4872],\n",
            "        [-0.6555, -0.1202],\n",
            "        [ 0.4907,  0.5229],\n",
            "        [-0.4818,  0.5152]], device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.6059, -0.3664, -0.3488,  0.2570, -0.4900], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0455, -0.1971, -0.3817,  0.2707,  0.1970],\n",
            "        [-0.3687, -0.3841, -0.2834, -0.1866, -0.3692],\n",
            "        [-0.0723, -0.2126,  0.3957, -0.3226, -0.0748],\n",
            "        [-0.3706, -0.0668, -0.2493,  0.0368, -0.0211],\n",
            "        [ 0.2951, -0.0035, -0.2387,  0.2200, -0.0834]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.3126,  0.2648, -0.0284, -0.2545,  0.3206], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[ 0.0796,  0.0458, -0.3610,  0.0517,  0.4346]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.3093], device='cuda:0', requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJnryBGCj8da",
        "colab_type": "text"
      },
      "source": [
        "We define our *loss function*, *learning rate*, and our *optimizer*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSM7o32MRmZQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_fn = nn.MSELoss(reduction='mean') #default\n",
        "learning_rate = 0.1\n",
        "optimizer = optim.Adagrad(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7y80N-dmkVFK",
        "colab_type": "text"
      },
      "source": [
        "Here is our training loop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jInSwhL8RmcY",
        "colab_type": "code",
        "outputId": "4be1bcae-2fa6-485c-fb6a-0818deb3d0fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "    # training\n",
        "    output = model(x_train_tensor)\n",
        "    loss = loss_fn(output, y_train_tensor)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    # testing\n",
        "    yhat = model(x_val_tensor)\n",
        "    validation_loss = loss_fn(yhat, y_val_tensor)\n",
        "    # print intermediate results\n",
        "    if epoch % 10 == 9:\n",
        "        print(epoch, loss.item(), validation_loss.item())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9 7.365058898925781 12.146252632141113\n",
            "19 6.494891166687012 10.409762382507324\n",
            "29 6.211064338684082 9.872771263122559\n",
            "39 5.948689937591553 9.375182151794434\n",
            "49 5.702565670013428 8.90356159210205\n",
            "59 5.4718708992004395 8.4547758102417\n",
            "69 5.2584710121154785 8.030385971069336\n",
            "79 5.065769195556641 7.634967803955078\n",
            "89 4.897581100463867 7.27454137802124\n",
            "99 4.756939888000488 6.954959869384766\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDl8eHfleK_C",
        "colab_type": "text"
      },
      "source": [
        "We can generalize some of the code inside the `for` loop. We'll define a template for our `fit_model` function that contains `train` and `validate` functions. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amLbK4yBRmfg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit_model(model, loss_fn, optimizer):\n",
        "    def train(x,y):\n",
        "        yhat = model(x)\n",
        "        loss = loss_fn(yhat,y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        return loss.item()\n",
        "    \n",
        "    def validate(x,y):\n",
        "        yhat = model(x)\n",
        "        loss = loss_fn(yhat,y)\n",
        "        return loss.item()\n",
        "    \n",
        "    return train, validate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2NAjWtvkIa6",
        "colab_type": "text"
      },
      "source": [
        " We pass our model, loss function, and optimizer to `fit_model` to return our `train` and `validate` functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k49SNPv4Rmi3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, validate = fit_model(model, loss_fn, optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoY2RMROeg4A",
        "colab_type": "text"
      },
      "source": [
        "## Mini-batches\n",
        "\n",
        "From the documentation: `torch.nn` only supports mini-batches. The entire `torch.nn` package only supports inputs that are a mini-batch of samples, and not a single sample."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfkZGCz7RmmA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = TensorDataset(x_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(dataset=train_data, batch_size=10, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pU9J7-E9kgXi",
        "colab_type": "text"
      },
      "source": [
        "Here is our training loop with mini-batch processing. We have to move each mini-batch onto the GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yweeH2KERmpC",
        "colab_type": "code",
        "outputId": "b4f8395b-f9c2-4579-bfd0-15ecda99539b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "    # training\n",
        "    losses = []\n",
        "    for i, (xbatch, ybatch) in enumerate(train_loader):\n",
        "        xbatch = xbatch.to(device)\n",
        "        ybatch = ybatch.to(device)\n",
        "        loss = train(xbatch, ybatch)\n",
        "        losses.append(loss)\n",
        "    training_loss = np.mean(losses)\n",
        "    # validation\n",
        "    validation_loss = validate(x_val_tensor, y_val_tensor)\n",
        "    if epoch%10 == 9:\n",
        "        print(epoch, training_loss, validation_loss)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9 4.431602434678511 5.717512130737305\n",
            "19 4.4578500660983 5.79561185836792\n",
            "29 4.42373438314958 5.699330806732178\n",
            "39 4.4469006061553955 5.70211124420166\n",
            "49 4.433960112658414 5.681665420532227\n",
            "59 4.442956664345481 5.705132961273193\n",
            "69 4.463378797877919 5.76559591293335\n",
            "79 4.430946686051109 5.709566116333008\n",
            "89 4.428162076256492 5.758986949920654\n",
            "99 4.425388639623469 5.7122626304626465\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMIPmGVBlISA",
        "colab_type": "text"
      },
      "source": [
        "We can view the current state of our model using the `state_dict` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXP_8gPQlHtL",
        "colab_type": "code",
        "outputId": "25873316-1b31-4ad1-d875-e32e319cf4b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "model.state_dict()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('0.weight', tensor([[-0.1215, -0.3991],\n",
              "                      [ 0.1468,  0.3617],\n",
              "                      [-0.6555, -0.1202],\n",
              "                      [ 2.2297, -0.1139],\n",
              "                      [-0.4818,  0.5152]], device='cuda:0')),\n",
              "             ('0.bias',\n",
              "              tensor([-0.6059, -0.4847, -0.3488,  0.3747, -0.4900], device='cuda:0')),\n",
              "             ('2.weight',\n",
              "              tensor([[-0.0455, -0.0129, -0.3817,  1.2829,  0.1970],\n",
              "                      [-0.3687, -0.2262, -0.2834,  0.7972, -0.3692],\n",
              "                      [-0.0723, -0.2126,  0.3957, -0.3226, -0.0748],\n",
              "                      [-0.3706, -0.0668, -0.2493,  0.0368, -0.0211],\n",
              "                      [ 0.2951,  0.1044, -0.2387,  1.0469, -0.0834]], device='cuda:0')),\n",
              "             ('2.bias',\n",
              "              tensor([-0.1693,  0.5226, -0.0284, -0.2545,  0.5484], device='cuda:0')),\n",
              "             ('4.weight',\n",
              "              tensor([[ 1.0519,  0.7333, -0.3610,  0.0517,  1.0764]], device='cuda:0')),\n",
              "             ('4.bias', tensor([-0.0659], device='cuda:0'))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    }
  ]
}