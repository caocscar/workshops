{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Workshop CNN.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/caocscar/workshops/blob/master/pytorch/Workshop_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa28NQ4b50Wk",
        "colab_type": "text"
      },
      "source": [
        "# Image Classification Problem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WK-LdzWl5vH6",
        "colab_type": "code",
        "outputId": "9633651c-31d5-4c8e-a623-c1e209426f7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "\n",
        "print('Torch version', torch.__version__)\n",
        "print('Torchvision version', torchvision.__version__)\n",
        "print('Numpy version', np.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Torch version 1.3.1\n",
            "Torchvision version 0.4.2\n",
            "Numpy version 1.17.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKCLbDM754c0",
        "colab_type": "text"
      },
      "source": [
        "The following should say `cuda:0`. If it does not, we need to go to *Edit* -> *Notebook settings* and change it to a `GPU` from `None`. You only have to do this once per notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2RWBSbo53bz",
        "colab_type": "code",
        "outputId": "fa70a535-a31d-405b-90cd-5ccb15a4457a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhBlj7GI6Npt",
        "colab_type": "text"
      },
      "source": [
        "Define a transform to convert image to PyTorch tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIjSGCNv53fT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf = transforms.ToTensor() # convert image to PyTorch tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0p_SPGXQ6PaD",
        "colab_type": "text"
      },
      "source": [
        "Download training **dataset** and create `DataLoader`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5R_cuLZ53ib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = DataLoader(datasets.MNIST('data', download=True, train=True, transform=tf),\n",
        "                           batch_size=100, \n",
        "                           shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enL0Q9306QBM",
        "colab_type": "text"
      },
      "source": [
        "Download validation **dataset** and create `DataLoader`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASnI4ZrW53lj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_loader = DataLoader(datasets.MNIST('data', download=True, train=False, transform=tf),\n",
        "                           batch_size=100, \n",
        "                           shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttYvEnkb6Qkb",
        "colab_type": "text"
      },
      "source": [
        "We'll write a python class to define out convolutional neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBZtZhgy6TCk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TwoLayerCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.batchnorm = nn.BatchNorm2d(1)\n",
        "        self.conv1 = nn.Conv2d(1,4,5) # input image channel, output channels, square kernel size\n",
        "        self.conv2 = nn.Conv2d(4,16,5)\n",
        "        self.fc1 = nn.Linear(16*4*4,100) # fully connected, 4x4 image size result from 2 conv layers\n",
        "        self.fc2 = nn.Linear(100,10)\n",
        "        \n",
        "    def forward(self,x):\n",
        "        x1 = self.batchnorm(x)\n",
        "        x1 = F.max_pool2d(F.relu(self.conv1(x1)), 2)\n",
        "        x1 = F.max_pool2d(F.relu(self.conv2(x1)), 2)\n",
        "        x1 = x1.view(-1, self.num_flat_features(x1))\n",
        "        x1 = F.dropout(F.relu(self.fc1(x1), 0.4))\n",
        "        x1 = F.relu(self.fc2(x1))\n",
        "        return x1\n",
        "                      \n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = np.prod(size)\n",
        "        return num_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M54pEgD06RoL",
        "colab_type": "text"
      },
      "source": [
        "We create an instance of this class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVdKpsuh6TS0",
        "colab_type": "code",
        "outputId": "258fd01d-b5e0-4e50-d9fd-2655d7e04704",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "model = TwoLayerCNN().to(device)\n",
        "model"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TwoLayerCNN(\n",
              "  (batchnorm): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv1): Conv2d(1, 4, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv2): Conv2d(4, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=256, out_features=100, bias=True)\n",
              "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFRVmzOR6SB7",
        "colab_type": "text"
      },
      "source": [
        "We'll define a template for our `fit_model` function that contains `train`,  `validate`, and `accuracy` functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZnvxqPu53rs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit_model(model, loss_fn, optimizer):\n",
        "    def train(x,y):\n",
        "        yhat = model(x)\n",
        "        loss = loss_fn(yhat,y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        return loss.item(), accuracy(yhat,y)\n",
        "    \n",
        "    def validate(x,y):\n",
        "        yhat = model(x)\n",
        "        loss = loss_fn(yhat,y)\n",
        "        return loss.item(), accuracy(yhat,y)\n",
        "    \n",
        "    def accuracy(yhat,y):\n",
        "        probs = np.argmax(yhat.cpu().detach().numpy(), axis=1)\n",
        "        actual = y.cpu().detach().numpy()\n",
        "        correct = (probs == actual).sum()\n",
        "        total = y.shape[0]\n",
        "        return correct / total   \n",
        "    \n",
        "    return train, validate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCrMhx8Q6TLd",
        "colab_type": "text"
      },
      "source": [
        "We define our *loss function*, *learning rate*, and our *optimizer*. We pass this to `fit_model` to return our `train` and `validate` functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFBR4YbD53oz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "learning_rate = 0.01\n",
        "optimizer = optim.Adagrad(model.parameters(), lr=learning_rate)\n",
        "train, validate = fit_model(model, loss_fn, optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNVzkMZI6Tam",
        "colab_type": "text"
      },
      "source": [
        "Here is our training loop with mini-batch processing. We have to move each batch onto the GPU. We also should have a `DataLoader` for the validation dataset but we'll skip that in this case since it is so small."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKk5nZjM6Ths",
        "colab_type": "code",
        "outputId": "8a867760-9fc7-45de-8398-08b25a395c4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    # training    \n",
        "    losses, accuracy = [], []\n",
        "    for i, (xbatch, ybatch) in enumerate(train_loader):\n",
        "        xbatch = xbatch.to(device)\n",
        "        ybatch = ybatch.to(device)\n",
        "        loss, acc = train(xbatch, ybatch)\n",
        "        losses.append(loss)\n",
        "        accuracy.append(acc)\n",
        "    training_loss = np.mean(losses)\n",
        "    training_accuracy = np.mean(accuracy)\n",
        "    # validation\n",
        "    val_losses, val_accuracy = [], []\n",
        "    for j, (xtest, ytest) in enumerate(test_loader):\n",
        "        xtest = xtest.to(device)\n",
        "        ytest = ytest.to(device)\n",
        "        val_loss, val_acc = validate(xtest, ytest)\n",
        "        val_losses.append(val_loss)\n",
        "        val_accuracy.append(val_acc)\n",
        "    validation_loss = np.mean(val_losses)\n",
        "    validation_accuracy = np.mean(val_accuracy)\n",
        "    # print intermediate results\n",
        "    print(f'{epoch}, {training_loss:.4f}, {training_accuracy:.3f}, {validation_loss:.4f}, {validation_accuracy:.3f}')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0, 0.3363, 0.899, 0.1599, 0.954\n",
            "1, 0.1516, 0.956, 0.1300, 0.961\n",
            "2, 0.1271, 0.963, 0.1067, 0.965\n",
            "3, 0.1139, 0.967, 0.1046, 0.969\n",
            "4, 0.1044, 0.970, 0.0955, 0.972\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AudSc0uAqt9",
        "colab_type": "text"
      },
      "source": [
        "### nn.Sequential\n",
        "\n",
        "If we wanted to user the simpler `nn.Sequential` function, our model construction would have looked like this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlIMzvDyAq3U",
        "colab_type": "code",
        "outputId": "eb88f17a-b8e3-4089-d468-7fb01d45c00c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "model_sequential = nn.Sequential(\n",
        "    nn.BatchNorm2d(1),\n",
        "    nn.Conv2d(1,4,5),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2),\n",
        "    nn.Conv2d(4,16,5),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2),\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(256,100),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.4),\n",
        "    nn.Linear(100,10),\n",
        "    nn.Softmax(dim=1),\n",
        ").to(device)\n",
        "model_sequential"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (1): Conv2d(1, 4, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (2): ReLU()\n",
              "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (4): Conv2d(4, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (5): ReLU()\n",
              "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (7): Flatten()\n",
              "  (8): Linear(in_features=256, out_features=100, bias=True)\n",
              "  (9): ReLU()\n",
              "  (10): Dropout(p=0.4, inplace=False)\n",
              "  (11): Linear(in_features=100, out_features=10, bias=True)\n",
              "  (12): Softmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    }
  ]
}