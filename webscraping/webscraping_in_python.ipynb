{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copying and pasting is great. You should definitely use it if it's the simplest way. But if you don't want to copy and paste 10 webpages into Excel or if you have some time to kill, then web scraping is the answer or time sink you've been looking for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing the python modules that we will need to do web scraping. We will be using `requests` to fetch html pages and `BeautifulSoup` to parse the html page. `pandas` will be used for data manipulation. The `pd.options.display` lines are for formatting purposes when printing out results in `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_rows = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: Wikipedia Page (HTML Table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by opening the <a href='https://en.wikipedia.org/wiki/List_of_Michigan_locations_by_per_capita_income'>website of interest</a> in a browser. We can see that it looks nicely formatted like a table. We start with passing the website of interest to the `requests.get` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = r'https://en.wikipedia.org/wiki/List_of_Michigan_locations_by_per_capita_income'\n",
    "R = requests.get(url)\n",
    "R.raise_for_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Without the `R.raise_for_status()` line, bad urls will fail silently which is probably not what you want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use `BeautifulSoup` to parse the contents of the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(R.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I like to use the browser's developer tool to do the detective work of figuring out where the data resides (*right click -> Inspect*). In this example, the data of interest resides in a html table (makes life easier)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the data of interest resides in a table tag &lt;table&gt;. To grab everything between the table tags, we use the `find_all` method (one of many options but probably the only one you need and the one you will use most often)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tables = soup.find_all('table')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`find_all` returns a list of matches. We can use the `len` function to see how many matches came back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the contents of the table using the `text` method. It will be a formatting mess but that's okay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nThis article is part of a series on\\n\\n\\nIncome in the\\nUnited States of America\\n\\n\\n\\n\\n\\n\\n\\nTopics\\n\\n\\nHousehold\\nPersonal\\nAffluence\\n\\n\\nSocial class\\nIncome inequality\\n\\ngender pay gap\\nethnic wage gap\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLists by income\\n\\n\\nStates (by equality (Gini))\\nCounties (highest\\xa0/ lowest)\\nLocations (lowest)\\nMetropolitan statistical areas\\n\\n\\nUrban areas\\nZIP Code Tabulation Areas\\n\\n\\n\\n\\n\\n\\n United States portal\\n\\n\\n\\n\\n\\nv\\nt\\ne\\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nRank\\nCounty\\nPer capita\\nincome\\nMedian\\nhousehold\\nincome\\nMedian\\nfamily\\nincome\\nPopulation\\nNumber of\\nhouseholds\\n\\n\\n1\\nOakland\\n$56,138\\n$85,991\\n$94,783\\n1,202,362\\n483,698\\n\\n\\n2\\nLeelanau\\n$32,194\\n$56,527\\n$65,342\\n21,708\\n9,255\\n\\n\\n3\\nLivingston\\n$31,609\\n$72,129\\n$82,637\\n180,967\\n67,380\\n\\n\\n4\\nWashtenaw\\n$31,316\\n$59,065\\n$82,184\\n344,791\\n137,193\\n\\n\\n5\\nCharlevoix\\n$28,403\\n$48,704\\n$57,022\\n25,949\\n10,882\\n\\n\\n6\\nMidland\\n$28,363\\n$51,103\\n$63,299\\n83,629\\n33,437\\n\\n\\n7\\nEmmet\\n$28,308\\n$49,235\\n$61,600\\n32,694\\n13,601\\n\\n\\n\\nUnited States\\n$27,334\\n$51,914\\n$62,982\\n308,745,538\\n116,716,292\\n\\n\\n8\\nClinton\\n$27,223\\n$58,016\\n$69,611\\n75,382\\n28,766\\n\\n\\n9\\nGrand Traverse\\n$27,091\\n$50,647\\n$61,780\\n86,986\\n35,328\\n\\n\\n10\\nMacomb\\n$26,524\\n$53,996\\n$67,423\\n840,978\\n331,667\\n\\n\\n11\\nEaton\\n$25,963\\n$54,885\\n$66,788\\n107,759\\n43,494\\n\\n\\n12\\nMonroe\\n$25,520\\n$55,366\\n$66,549\\n152,021\\n58,230\\n\\n\\n13\\nKalamazoo\\n$25,138\\n$44,794\\n$61,622\\n250,331\\n100,610\\n\\n\\n\\nMichigan\\n$25,135\\n$48,432\\n$60,341\\n9,883,640\\n3,872,508\\n\\n\\n14\\nLapeer\\n$25,110\\n$55,005\\n$63,061\\n88,319\\n32,776\\n\\n\\n15\\nOttawa\\n$25,045\\n$55,095\\n$65,474\\n263,801\\n93,775\\n\\n\\n16\\nKent\\n$24,791\\n$49,532\\n$61,097\\n602,622\\n227,239\\n\\n\\n17\\nBarry\\n$24,493\\n$51,869\\n$61,202\\n59,173\\n22,551\\n\\n\\n18\\nBerrien\\n$24,025\\n$42,625\\n$54,751\\n156,813\\n63,054\\n\\n\\n19\\nAntrim\\n$23,912\\n$43,123\\n$50,424\\n23,580\\n9,890\\n\\n\\n20\\nIngham\\n$23,883\\n$45,808\\n$61,680\\n280,895\\n111,162\\n\\n\\n21\\nDickinson\\n$23,854\\n$42,586\\n$54,053\\n26,168\\n11,359\\n\\n\\n22\\nSt. Clair\\n$23,828\\n$49,120\\n$59,969\\n163,040\\n63,841\\n\\n\\n23\\nBenzie\\n$23,649\\n$44,718\\n$53,250\\n17,525\\n7,298\\n\\n\\n24\\nMarquette\\n$23,347\\n$45,130\\n$61,798\\n67,077\\n27,538\\n\\n\\n25\\nAllegan\\n$23,108\\n$50,240\\n$57,831\\n111,408\\n42,018\\n\\n\\n26\\nBay\\n$23,049\\n$44,659\\n$53,824\\n107,771\\n44,603\\n\\n\\n27\\nCheboygan\\n$23,038\\n$37,903\\n$45,769\\n26,152\\n11,133\\n\\n\\n28\\nCass\\n$22,698\\n$45,177\\n$54,813\\n52,293\\n20,604\\n\\n\\n29\\nOtsego\\n$22,568\\n$45,531\\n$54,110\\n24,164\\n9,756\\n\\n\\n30\\nLenawee\\n$22,529\\n$48,618\\n$60,028\\n99,892\\n37,514\\n\\n\\n31\\nGenesee\\n$22,458\\n$43,483\\n$54,072\\n425,790\\n169,202\\n\\n\\n32\\nMackinac\\n$22,170\\n$39,339\\n$51,376\\n11,113\\n5,024\\n\\n\\n33\\nCalhoun\\n$22,166\\n$42,568\\n$52,533\\n136,146\\n54,016\\n\\n\\n34\\nWayne\\n$22,125\\n$42,241\\n$52,946\\n1,820,584\\n702,749\\n\\n\\n35\\nHuron\\n$22,098\\n$40,038\\n$49,444\\n33,118\\n14,348\\n\\n\\n36\\nDelta\\n$22,064\\n$41,951\\n$51,442\\n37,069\\n15,992\\n\\n\\n37\\nVan Buren\\n$22,002\\n$44,435\\n$54,499\\n76,258\\n28,928\\n\\n\\n38\\nJackson\\n$21,947\\n$46,117\\n$56,314\\n160,248\\n60,771\\n\\n\\n39\\nShiawassee\\n$21,869\\n$46,453\\n$54,363\\n70,648\\n27,481\\n\\n\\n40\\nMason\\n$21,760\\n$40,039\\n$49,131\\n28,705\\n11,940\\n\\n\\n41\\nSaginaw\\n$21,662\\n$42,954\\n$53,171\\n200,169\\n79,011\\n\\n\\n42\\nMenominee\\n$21,624\\n$41,332\\n$49,394\\n24,029\\n10,474\\n\\n\\n43\\nManistee\\n$21,612\\n$40,853\\n$50,101\\n24,733\\n10,308\\n\\n\\n44\\nOntonagon\\n$21,448\\n$35,269\\n$47,330\\n6,780\\n3,258\\n\\n\\n45\\nKeweenaw\\n$21,307\\n$38,872\\n$46,414\\n2,156\\n1,013\\n\\n\\n46\\nAlpena\\n$21,140\\n$36,695\\n$47,256\\n29,598\\n12,791\\n\\n\\n47\\nCrawford\\n$21,002\\n$39,665\\n$45,362\\n14,074\\n6,016\\n\\n\\n48\\nNewaygo\\n$20,870\\n$43,218\\n$49,499\\n48,460\\n18,406\\n\\n\\n49\\nPresque Isle\\n$20,870\\n$37,383\\n$43,797\\n13,376\\n5,982\\n\\n\\n50\\nGladwin\\n$20,571\\n$37,936\\n$44,427\\n25,692\\n10,753\\n\\n\\n51\\nIosco\\n$20,513\\n$36,861\\n$44,175\\n25,887\\n11,757\\n\\n\\n52\\nSchoolcraft\\n$20,455\\n$36,925\\n$48,141\\n8,485\\n3,759\\n\\n\\n53\\nChippewa\\n$20,309\\n$40,194\\n$54,066\\n38,520\\n14,329\\n\\n\\n54\\nRoscommon\\n$20,194\\n$33,542\\n$40,015\\n24,449\\n11,433\\n\\n\\n55\\nSt. Joseph\\n$20,192\\n$44,392\\n$52,586\\n61,295\\n23,244\\n\\n\\n56\\nHillsdale\\n$20,006\\n$42,989\\n$50,546\\n46,688\\n17,792\\n\\n\\n57\\nIron\\n$19,986\\n$33,734\\n$44,560\\n11,817\\n5,577\\n\\n\\n58\\nWexford\\n$19,952\\n$39,997\\n$46,659\\n32,735\\n13,021\\n\\n\\n59\\nTuscola\\n$19,937\\n$42,198\\n$50,262\\n55,729\\n21,590\\n\\n\\n60\\nGogebic\\n$19,933\\n$33,673\\n$45,182\\n16,427\\n7,037\\n\\n\\n61\\nAlcona\\n$19,904\\n$34,858\\n$43,482\\n10,942\\n5,089\\n\\n\\n62\\nAlger\\n$19,858\\n$38,262\\n$47,548\\n9,601\\n3,898\\n\\n\\n63\\nKalkaska\\n$19,770\\n$39,350\\n$45,417\\n17,153\\n6,962\\n\\n\\n64\\nMuskegon\\n$19,719\\n$40,670\\n$50,101\\n172,188\\n65,616\\n\\n\\n65\\nSanilac\\n$19,645\\n$40,818\\n$49,005\\n43,114\\n17,132\\n\\n\\n66\\nMissaukee\\n$19,560\\n$40,376\\n$46,371\\n14,849\\n5,843\\n\\n\\n67\\nIonia\\n$19,386\\n$46,454\\n$54,595\\n63,905\\n22,144\\n\\n\\n68\\nBaraga\\n$19,107\\n$40,541\\n$50,549\\n8,860\\n3,444\\n\\n\\n69\\nMontmorency\\n$19,102\\n$34,447\\n$41,230\\n9,765\\n4,416\\n\\n\\n70\\nArenac\\n$19,073\\n$36,689\\n$45,376\\n15,899\\n6,701\\n\\n\\n71\\nBranch\\n$19,049\\n$42,133\\n$50,931\\n45,248\\n16,419\\n\\n\\n72\\nMecosta\\n$18,745\\n$35,887\\n$48,145\\n42,798\\n16,101\\n\\n\\n73\\nMontcalm\\n$18,569\\n$39,775\\n$46,673\\n63,342\\n23,432\\n\\n\\n74\\nOscoda\\n$18,524\\n$32,346\\n$39,335\\n8,640\\n3,772\\n\\n\\n75\\nIsabella\\n$18,510\\n$36,880\\n$55,183\\n70,311\\n25,586\\n\\n\\n76\\nClare\\n$18,491\\n$34,399\\n$42,519\\n30,926\\n12,966\\n\\n\\n77\\nOceana\\n$18,402\\n$39,543\\n$46,424\\n26,570\\n10,174\\n\\n\\n78\\nGratiot\\n$18,388\\n$40,114\\n$49,989\\n42,476\\n14,852\\n\\n\\n79\\nOgemaw\\n$18,321\\n$35,968\\n$41,810\\n21,699\\n9,283\\n\\n\\n80\\nHoughton\\n$18,267\\n$34,174\\n$46,819\\n36,628\\n14,232\\n\\n\\n81\\nOsceola\\n$17,861\\n$38,341\\n$44,613\\n23,528\\n9,222\\n\\n\\n82\\nLuce\\n$17,195\\n$40,041\\n$46,510\\n6,631\\n2,412\\n\\n\\n83\\nLake\\n$16,084\\n$31,205\\n$38,996\\n11,539\\n5,158\\n\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables[1].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like this is the table we want. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A better way to find the table of interest is to pass in extra search terms to the `find_all` method after using the developer tool to find searchable attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables = soup.find_all('table', class_=\"wikitable sortable\")\n",
    "len(tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get one result instead of three."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table = tables[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data resides in a html table standard cell tag `<td>` within a table row tag `<tr>`. We use `find_all` to look for all the table row tags within the table tag `<table>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_rows = table.find_all('tr')\n",
    "len(table_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now see that there are a lot of matches for that tag, as expected. It's close to the total number of countries. Let's look at the first few entries of `table_rows`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tr valign=\"bottom\">\n",
       "<th>Rank</th>\n",
       "<th>County</th>\n",
       "<th>Per capita<br/>\n",
       "income</th>\n",
       "<th>Median<br/>\n",
       "household<br/>\n",
       "income</th>\n",
       "<th>Median<br/>\n",
       "family<br/>\n",
       "income</th>\n",
       "<th>Population</th>\n",
       "<th>Number of<br/>\n",
       "households</th>\n",
       "</tr>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_rows[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the header row. The `<th>` tag also gives it away, fyi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tr>\n",
       "<td>1</td>\n",
       "<td><a href=\"/wiki/Oakland_County,_Michigan\" title=\"Oakland County, Michigan\">Oakland</a></td>\n",
       "<td>$56,138</td>\n",
       "<td>$85,991</td>\n",
       "<td>$94,783</td>\n",
       "<td>1,202,362</td>\n",
       "<td>483,698</td>\n",
       "</tr>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_rows[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its the row data for the __first county__. \n",
    "\n",
    "We will use a nested `for` loop to go through the list of table rows. The inner `for` loop will go through each `<td>` tag appending the text to a list. We will grab all the data in the tags regardless of whether we want to keep them for now. \n",
    "\n",
    "We have two lists in the `for` loop. `row` will contain a list of the each `td` tag in a table row. Once the row is iterated through, we will convert it to a `pandas` dataframe. `list_df` will contain a list of those dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_df = []\n",
    "for row in table_rows:\n",
    "    table_cells = row.find_all('td')\n",
    "    row = []\n",
    "    for cell in table_cells:\n",
    "        row.append(cell.text)    \n",
    "    list_df.append(pd.DataFrame(row).transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take the list of dataframes and concatenate them together into one dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.concat(list_df, ignore_index=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the first 5 rows of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Oakland</td>\n",
       "      <td>$56,138</td>\n",
       "      <td>$85,991</td>\n",
       "      <td>$94,783</td>\n",
       "      <td>1,202,362</td>\n",
       "      <td>483,698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Leelanau</td>\n",
       "      <td>$32,194</td>\n",
       "      <td>$56,527</td>\n",
       "      <td>$65,342</td>\n",
       "      <td>21,708</td>\n",
       "      <td>9,255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Livingston</td>\n",
       "      <td>$31,609</td>\n",
       "      <td>$72,129</td>\n",
       "      <td>$82,637</td>\n",
       "      <td>180,967</td>\n",
       "      <td>67,380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Washtenaw</td>\n",
       "      <td>$31,316</td>\n",
       "      <td>$59,065</td>\n",
       "      <td>$82,184</td>\n",
       "      <td>344,791</td>\n",
       "      <td>137,193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Charlevoix</td>\n",
       "      <td>$28,403</td>\n",
       "      <td>$48,704</td>\n",
       "      <td>$57,022</td>\n",
       "      <td>25,949</td>\n",
       "      <td>10,882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0           1        2        3        4          5        6\n",
       "0  1     Oakland  $56,138  $85,991  $94,783  1,202,362  483,698\n",
       "1  2    Leelanau  $32,194  $56,527  $65,342     21,708    9,255\n",
       "2  3  Livingston  $31,609  $72,129  $82,637    180,967   67,380\n",
       "3  4   Washtenaw  $31,316  $59,065  $82,184    344,791  137,193\n",
       "4  5  Charlevoix  $28,403  $48,704  $57,022     25,949   10,882"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We didn't get the header row because it was contained in `<th>` tags and not `<td>` tags. We use the same type of `for` loop to extract the text from the table headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "headers = table_rows[0].find_all('th')\n",
    "columns = []\n",
    "for header in headers:\n",
    "    columns.append(header.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the column headers of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>County</th>\n",
       "      <th>Per capita\n",
       "income</th>\n",
       "      <th>Median\n",
       "household\n",
       "income</th>\n",
       "      <th>Median\n",
       "family\n",
       "income</th>\n",
       "      <th>Population</th>\n",
       "      <th>Number of\n",
       "households</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Oakland</td>\n",
       "      <td>$56,138</td>\n",
       "      <td>$85,991</td>\n",
       "      <td>$94,783</td>\n",
       "      <td>1,202,362</td>\n",
       "      <td>483,698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Leelanau</td>\n",
       "      <td>$32,194</td>\n",
       "      <td>$56,527</td>\n",
       "      <td>$65,342</td>\n",
       "      <td>21,708</td>\n",
       "      <td>9,255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Livingston</td>\n",
       "      <td>$31,609</td>\n",
       "      <td>$72,129</td>\n",
       "      <td>$82,637</td>\n",
       "      <td>180,967</td>\n",
       "      <td>67,380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Washtenaw</td>\n",
       "      <td>$31,316</td>\n",
       "      <td>$59,065</td>\n",
       "      <td>$82,184</td>\n",
       "      <td>344,791</td>\n",
       "      <td>137,193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Charlevoix</td>\n",
       "      <td>$28,403</td>\n",
       "      <td>$48,704</td>\n",
       "      <td>$57,022</td>\n",
       "      <td>25,949</td>\n",
       "      <td>10,882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rank      County Per capita\\nincome Median\\nhousehold\\nincome  \\\n",
       "0    1     Oakland            $56,138                   $85,991   \n",
       "1    2    Leelanau            $32,194                   $56,527   \n",
       "2    3  Livingston            $31,609                   $72,129   \n",
       "3    4   Washtenaw            $31,316                   $59,065   \n",
       "4    5  Charlevoix            $28,403                   $48,704   \n",
       "\n",
       "  Median\\nfamily\\nincome Population Number of\\nhouseholds  \n",
       "0                $94,783  1,202,362               483,698  \n",
       "1                $65,342     21,708                 9,255  \n",
       "2                $82,637    180,967                67,380  \n",
       "3                $82,184    344,791               137,193  \n",
       "4                $57,022     25,949                10,882  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns = columns\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have all the data of interest. __Webscraping DONE!__ If you want to do some data cleanup and management (like remove dollar sign and commas, this is where `pandas` becomes useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the data to a txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_csv('wikipedia_micounties_income.txt', sep='|', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at the text file, there is some more data cleanup we could have done but I'm not here to teach you how to do that with `pandas` (although we do have workshops to do just that)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pandas` Approach to HTML Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pandas `read_html` method can read in HTML Tables (and only HTML Tables). It uses `BeautifulSoup` under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_tables = pd.read_html(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: If you get an `ImportError: html5lib not found, please install it` message, you will need to install it via `conda install html5lib` and you might need to restart the kernel or Juypter Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns a list of dataframes. One dataframe for each table in the html page. Recall how many tables there were. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check their contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rank</td>\n",
       "      <td>County</td>\n",
       "      <td>Per capita income</td>\n",
       "      <td>Median household income</td>\n",
       "      <td>Median family income</td>\n",
       "      <td>Population</td>\n",
       "      <td>Number of households</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Oakland</td>\n",
       "      <td>$56,138</td>\n",
       "      <td>$85,991</td>\n",
       "      <td>$94,783</td>\n",
       "      <td>1202362</td>\n",
       "      <td>483698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Leelanau</td>\n",
       "      <td>$32,194</td>\n",
       "      <td>$56,527</td>\n",
       "      <td>$65,342</td>\n",
       "      <td>21708</td>\n",
       "      <td>9255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Livingston</td>\n",
       "      <td>$31,609</td>\n",
       "      <td>$72,129</td>\n",
       "      <td>$82,637</td>\n",
       "      <td>180967</td>\n",
       "      <td>67380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Washtenaw</td>\n",
       "      <td>$31,316</td>\n",
       "      <td>$59,065</td>\n",
       "      <td>$82,184</td>\n",
       "      <td>344791</td>\n",
       "      <td>137193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0           1                  2                        3  \\\n",
       "0  Rank      County  Per capita income  Median household income   \n",
       "1     1     Oakland            $56,138                  $85,991   \n",
       "2     2    Leelanau            $32,194                  $56,527   \n",
       "3     3  Livingston            $31,609                  $72,129   \n",
       "4     4   Washtenaw            $31,316                  $59,065   \n",
       "\n",
       "                      4           5                     6  \n",
       "0  Median family income  Population  Number of households  \n",
       "1               $94,783     1202362                483698  \n",
       "2               $65,342       21708                  9255  \n",
       "3               $82,637      180967                 67380  \n",
       "4               $82,184      344791                137193  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_tables[1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same table contains our data of interest (as expected). It leaves us at a similiar point that we encountered earlier in the example. `pandas` has basically done the web scraping for us and left us with the data cleanup and wrangling. You should always expect to do some data manipulation if you use the `pd.read_html()` method or any webscraping for that matter.\n",
    "\n",
    "Q: So why did we learn a more complicated way of doing things when `pd.read_html()` can do it for you?  \n",
    "A: Because not everything resides in an HTML table and you'll need to use the same techniques to get at the data. If the data resides in a HTML table, consider yourself fortunate, use `pandas` and move on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape Serena Williams' Wikipedia page https://en.wikipedia.org/wiki/Serena_Williams for the data in the html table **Grand Slam tournament finals**  for *Singles* in the *Career Statistics* section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2: USA TODAY Best Selling Books (not in HTML Table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the website of interest is https://www.usatoday.com/life/books/best-selling/. Suppose we are interested in getting some basic information about the book list. For this example, the data of interest does not exist in a html table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with the boilerplate template of passing the website of interest to the `requests.get` method. We then use `BeautifulSoup` to parse the contents of the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = r'https://www.usatoday.com/life/books/best-selling/'\n",
    "R = requests.get(url)\n",
    "R.raise_for_status()\n",
    "soup = BeautifulSoup(R.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Navigate to the website and use the browser's developer tool to inspect items of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data seems to be residing in a `div` tag. Let's search for that and the class info and see how many matches we get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "booklist = soup.find_all('div', class_=\"front-booklist-info-container\")\n",
    "len(booklist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the text associated within each `<div>` book tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1The President Is MissingbyJames Patterson, Bill ClintonThe U.S. president disappears as a cyberterrorist threat grips the nation \r\n",
      "Genre:General fictionDebuted:June 14 2018\n",
      "                            Buy Now\n",
      "                        \n",
      "                                    Buy Now\n",
      "                                AmazonBarnes & NobleGoogle PlayiBooksIndieboundKoboZola1Weeks Listed#1Best Week\n",
      "1 2The OutsiderbyStephen KingThe arrest of a Little League coach for the murder of a local boy leads investigators to an unexpected villainGenre:General fictionDebuted:May 31 2018\n",
      "                            Buy Now\n",
      "                        \n",
      "                                    Buy Now\n",
      "                                AmazonBarnes & NobleGoogle PlayiBooksIndieboundKoboZola#2Last Week3Weeks Listed#1Best Week\n",
      "2 3Kitchen Confidential: Adventures in the Culinary UnderbellybyAnthony BourdainThis 2000 memoir by the late chef and travel show host offers a candid look inside restaurant kitchensGenre:CookbooksDebuted:June 01 2000\n",
      "                            Buy Now\n",
      "                        \n",
      "                                    Buy Now\n",
      "                                AmazonBarnes & NobleGoogle PlayiBooksIndieboundKoboZolaRead an excerptpowered by Zola24Weeks Listed#3Best Week\n",
      "3 4Shelter in PlacebyNora RobertsSurvivors of a horrific mall shooting in Portland, Maine, find themselves targeted again years laterGenre:RomanceDebuted:June 07 2018\n",
      "                            Buy Now\n",
      "                        \n",
      "                                    Buy Now\n",
      "                                AmazonBarnes & NobleGoogle PlayiBooksIndieboundKoboZola#1Last Week2Weeks Listed#1Best Week\n",
      "4 5 TurbulencebyStuart WoodsWhile on vacation, Stone Barrington investigates a crooked politician; 46th in seriesGenre:General fictionDebuted:June 14 2018\n",
      "                            Buy Now\n",
      "                        \n",
      "                                    Buy Now\n",
      "                                AmazonBarnes & NobleGoogle PlayiBooksIndieboundKoboZola1Weeks Listed#5Best Week\n",
      "5 6Magnolia TablebyJoanna Gaines, Marah StetsSubtitle: \"A Collection of Recipes for Gathering\"Genre:CookbooksDebuted:May 03 2018\n",
      "                            Buy Now\n",
      "                        \n",
      "                                    Buy Now\n",
      "                                AmazonBarnes & NobleGoogle PlayiBooksIndieboundKoboZola#7Last Week7Weeks Listed#1Best Week\n",
      "6 7Oh, the Places You’ll Go!byDr. SeussChildren: Dr. Seuss’ advice on life is a favorite for graduationsGenre:ChildrenDebuted:December 23 1993\n",
      "                            Buy Now\n",
      "                        \n",
      "                                    Buy Now\n",
      "                                AmazonBarnes & NobleGoogle PlayiBooksIndieboundKoboZola#5Last Week406Weeks Listed#1Best Week\n",
      "7 8Brief CasesbyJim ButcherStory collection about Harry Dresden, the only professional wizard in ChicagoGenre:General fictionDebuted:June 14 2018\n",
      "                            Buy Now\n",
      "                        \n",
      "                                    Buy Now\n",
      "                                AmazonBarnes & NobleGoogle PlayiBooksIndieboundKoboZola1Weeks Listed#8Best Week\n",
      "8 9When Life Gives You LululemonsbyLauren WeisbergerEmily Charlton tries to rehab the tarnished image of former supermodel Karolina HartwellGenre:General fictionDebuted:June 14 2018\n",
      "                            Buy Now\n",
      "                        \n",
      "                                    Buy Now\n",
      "                                AmazonBarnes & NobleGoogle PlayiBooksIndieboundKoboZola1Weeks Listed#9Best Week\n",
      "9 10Trump's AmericabyNewt GingrichSubtitle: \"The Truth About Our Nation's Great Comeback\"Genre:Current affairsDebuted:June 14 2018\n",
      "                            Buy Now\n",
      "                        \n",
      "                                    Buy Now\n",
      "                                AmazonBarnes & NobleGoogle PlayiBooksIndieboundKoboZola1Weeks Listed#10Best Week\n"
     ]
    }
   ],
   "source": [
    "for i, book in enumerate(booklist):\n",
    "    print(i, book.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want the title, author and genre. Let's use the browser to inspect which tags the data lies in. Then we'll use the `find_all` method to search for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. The President Is Missing, James Patterson, Bill Clinton, Genre:General fiction\n",
      "2. The Outsider, Stephen King, Genre:General fiction\n",
      "3. Kitchen Confidential: Adventures in the Culinary Underbelly, Anthony Bourdain, Genre:Cookbooks\n",
      "4. Shelter in Place, Nora Roberts, Genre:Romance\n",
      "5.  Turbulence, Stuart Woods, Genre:General fiction\n",
      "6. Magnolia Table, Joanna Gaines, Marah Stets, Genre:Cookbooks\n",
      "7. Oh, the Places You’ll Go!, Dr. Seuss, Genre:Children\n",
      "8. Brief Cases, Jim Butcher, Genre:General fiction\n",
      "9. When Life Gives You Lululemons, Lauren Weisberger, Genre:General fiction\n",
      "10. Trump's America, Newt Gingrich, Genre:Current affairs\n"
     ]
    }
   ],
   "source": [
    "for rank, book in enumerate(booklist, start=1):\n",
    "    title = book.find_all('h3', class_='books-front-meta-title')[0].text\n",
    "    author = book.find_all('span', class_='books-front-meta-authorInfo')[0].text\n",
    "    genre = book.find_all('div', class_='books-front-meta-genre')[0].text\n",
    "    print('{}. {}, {}, {}'.format(rank, title, author, genre))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Webscraping DONE! At least for page one. To scrape the rest of the pages, let's navigate to the other pages. Notice anything different in the url?\n",
    "\n",
    "Before: https://www.usatoday.com/life/books/best-selling/  \n",
    "After: https://www.usatoday.com/life/books/best-selling/week/2018/24/page/2/\n",
    "\n",
    "The **before url** is the webpage for the current bestseller list, page 1. The **after url** is for a specific week and page. We can use this format to scrape any page for any given week. Much more useful than the generic url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. The President Is Missing, James Patterson, Bill Clinton, Genre:General fiction\n",
      "2. The Outsider, Stephen King, Genre:General fiction\n",
      "3. Kitchen Confidential: Adventures in the Culinary Underbelly, Anthony Bourdain, Genre:Cookbooks\n",
      "4. Shelter in Place, Nora Roberts, Genre:Romance\n",
      "5.  Turbulence, Stuart Woods, Genre:General fiction\n",
      "6. Magnolia Table, Joanna Gaines, Marah Stets, Genre:Cookbooks\n",
      "7. Oh, the Places You’ll Go!, Dr. Seuss, Genre:Children\n",
      "8. Brief Cases, Jim Butcher, Genre:General fiction\n",
      "9. When Life Gives You Lululemons, Lauren Weisberger, Genre:General fiction\n",
      "10. Trump's America, Newt Gingrich, Genre:Current affairs\n",
      "11. The Sun Does Shine, Anthony Ray Hinton with Lara Love Hardin, Genre:Memoir\n",
      "12. The Plant Paradox, Steven R. Gundry, Genre:Diet/Health\n",
      "13. Calypso, David Sedaris, Genre:Memoir\n",
      "14. The Death of Mrs. Westaway, Ruth Ware, Genre:General fiction\n",
      "15. Something in the Water, Catherine Steadman, Genre:General fiction\n",
      "16. The Fallen, David Baldacci, Genre:General fiction\n",
      "17. The World as It Is, Ben Rhodes, Genre:Memoir\n",
      "18. The Subtle Art of Not Giving a (Expletive), Mark Manson, Genre:Psychology/Self-help\n",
      "19. Girl, Wash Your Face, Rachel Hollis, Genre:Psychology/Self-help\n",
      "20. The 17th Suspect, James Patterson, Maxine Paetro, Genre:General fiction\n",
      "21. After the Funeral, Agatha Christie, Genre:Mystery\n",
      "22. 12 Rules for Life: An Antidote to Chaos, Jordan B. Peterson, Genre:Psychology/Self-help\n",
      "23. Factfulness, Hans Rosling, Ola Rosling, Anna Rosling Rönnlund, Genre:Science/Technology\n",
      "24. Little Fires Everywhere, Celeste Ng, Genre:General fiction\n",
      "25. Trials of Apollo: The Burning Maze, Rick Riordan, Genre:Youth\n",
      "26. Before We Were Yours, Lisa Wingate, Genre:General fiction\n",
      "27. Crazy Rich Asians, Kevin Kwan, Genre:General fiction\n",
      "28. Us Against You, Fredrik Backman, Genre:General fiction\n",
      "29. Less, Andrew Sean Greer, Genre:General fiction\n",
      "30. The Gray Ghost, Clive Cussler, Robin Burcell, Genre:General fiction\n"
     ]
    }
   ],
   "source": [
    "rank = 0\n",
    "data = []\n",
    "for page in range(1,4):    \n",
    "    url = r'http://www.usatoday.com/life/books/best-selling/week/2018/24/page/{}/'.format(page)    \n",
    "    R = requests.get(url)\n",
    "    R.raise_for_status()\n",
    "    soup = BeautifulSoup(R.content, 'html.parser')\n",
    "    # find the element of interest matching our criteria\n",
    "    booklist = soup.find_all('div', class_='front-booklist-info-container')\n",
    "    for book in booklist:\n",
    "        title = book.find_all('h3', class_='books-front-meta-title')[0].text\n",
    "        author = book.find_all('span', class_='books-front-meta-authorInfo')[0].text\n",
    "        genre = book.find_all('div', class_='books-front-meta-genre')[0].text\n",
    "        rank += 1\n",
    "        print('{}. {}, {}, {}'.format(rank, title, author, genre))\n",
    "        data.append((rank,title,author,genre))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert the data into a `pandas` dataframe with column headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The President Is Missing</td>\n",
       "      <td>James Patterson, Bill Clinton</td>\n",
       "      <td>Genre:General fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>The Outsider</td>\n",
       "      <td>Stephen King</td>\n",
       "      <td>Genre:General fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Kitchen Confidential: Adventures in the Culina...</td>\n",
       "      <td>Anthony Bourdain</td>\n",
       "      <td>Genre:Cookbooks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Shelter in Place</td>\n",
       "      <td>Nora Roberts</td>\n",
       "      <td>Genre:Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Turbulence</td>\n",
       "      <td>Stuart Woods</td>\n",
       "      <td>Genre:General fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Before We Were Yours</td>\n",
       "      <td>Lisa Wingate</td>\n",
       "      <td>Genre:General fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Crazy Rich Asians</td>\n",
       "      <td>Kevin Kwan</td>\n",
       "      <td>Genre:General fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Us Against You</td>\n",
       "      <td>Fredrik Backman</td>\n",
       "      <td>Genre:General fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Less</td>\n",
       "      <td>Andrew Sean Greer</td>\n",
       "      <td>Genre:General fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>The Gray Ghost</td>\n",
       "      <td>Clive Cussler, Robin Burcell</td>\n",
       "      <td>Genre:General fiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank                                              title  \\\n",
       "0      1                           The President Is Missing   \n",
       "1      2                                       The Outsider   \n",
       "2      3  Kitchen Confidential: Adventures in the Culina...   \n",
       "3      4                                   Shelter in Place   \n",
       "4      5                                         Turbulence   \n",
       "..   ...                                                ...   \n",
       "25    26                               Before We Were Yours   \n",
       "26    27                                  Crazy Rich Asians   \n",
       "27    28                                     Us Against You   \n",
       "28    29                                               Less   \n",
       "29    30                                     The Gray Ghost   \n",
       "\n",
       "                           author                  genre  \n",
       "0   James Patterson, Bill Clinton  Genre:General fiction  \n",
       "1                    Stephen King  Genre:General fiction  \n",
       "2                Anthony Bourdain        Genre:Cookbooks  \n",
       "3                    Nora Roberts          Genre:Romance  \n",
       "4                    Stuart Woods  Genre:General fiction  \n",
       "..                            ...                    ...  \n",
       "25                   Lisa Wingate  Genre:General fiction  \n",
       "26                     Kevin Kwan  Genre:General fiction  \n",
       "27                Fredrik Backman  Genre:General fiction  \n",
       "28              Andrew Sean Greer  Genre:General fiction  \n",
       "29   Clive Cussler, Robin Burcell  Genre:General fiction  \n",
       "\n",
       "[30 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topsellers = pd.DataFrame(data, columns=['rank','title','author','genre'])\n",
    "topsellers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify the code below to scrape the entire list and add columns such as when it debuted and how long its been on the charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. The President Is Missing, James Patterson, Bill Clinton, Genre:General fiction\n",
      "2. The Outsider, Stephen King, Genre:General fiction\n",
      "3. Kitchen Confidential: Adventures in the Culinary Underbelly, Anthony Bourdain, Genre:Cookbooks\n",
      "4. Shelter in Place, Nora Roberts, Genre:Romance\n",
      "5.  Turbulence, Stuart Woods, Genre:General fiction\n",
      "6. Magnolia Table, Joanna Gaines, Marah Stets, Genre:Cookbooks\n",
      "7. Oh, the Places You’ll Go!, Dr. Seuss, Genre:Children\n",
      "8. Brief Cases, Jim Butcher, Genre:General fiction\n",
      "9. When Life Gives You Lululemons, Lauren Weisberger, Genre:General fiction\n",
      "10. Trump's America, Newt Gingrich, Genre:Current affairs\n",
      "11. The Sun Does Shine, Anthony Ray Hinton with Lara Love Hardin, Genre:Memoir\n",
      "12. The Plant Paradox, Steven R. Gundry, Genre:Diet/Health\n",
      "13. Calypso, David Sedaris, Genre:Memoir\n",
      "14. The Death of Mrs. Westaway, Ruth Ware, Genre:General fiction\n",
      "15. Something in the Water, Catherine Steadman, Genre:General fiction\n",
      "16. The Fallen, David Baldacci, Genre:General fiction\n",
      "17. The World as It Is, Ben Rhodes, Genre:Memoir\n",
      "18. The Subtle Art of Not Giving a (Expletive), Mark Manson, Genre:Psychology/Self-help\n",
      "19. Girl, Wash Your Face, Rachel Hollis, Genre:Psychology/Self-help\n",
      "20. The 17th Suspect, James Patterson, Maxine Paetro, Genre:General fiction\n",
      "21. After the Funeral, Agatha Christie, Genre:Mystery\n",
      "22. 12 Rules for Life: An Antidote to Chaos, Jordan B. Peterson, Genre:Psychology/Self-help\n",
      "23. Factfulness, Hans Rosling, Ola Rosling, Anna Rosling Rönnlund, Genre:Science/Technology\n",
      "24. Little Fires Everywhere, Celeste Ng, Genre:General fiction\n",
      "25. Trials of Apollo: The Burning Maze, Rick Riordan, Genre:Youth\n",
      "26. Before We Were Yours, Lisa Wingate, Genre:General fiction\n",
      "27. Crazy Rich Asians, Kevin Kwan, Genre:General fiction\n",
      "28. Us Against You, Fredrik Backman, Genre:General fiction\n",
      "29. Less, Andrew Sean Greer, Genre:General fiction\n",
      "30. The Gray Ghost, Clive Cussler, Robin Burcell, Genre:General fiction\n"
     ]
    }
   ],
   "source": [
    "rank = 0\n",
    "data = []\n",
    "for page in range(1,4):    \n",
    "    url = r'http://www.usatoday.com/life/books/best-selling/week/2018/24/page/{}/'.format(page)    \n",
    "    R = requests.get(url)\n",
    "    R.raise_for_status()\n",
    "    soup = BeautifulSoup(R.content, 'html.parser')\n",
    "    # find the element of interest matching our criteria\n",
    "    booklist = soup.find_all('div', class_='front-booklist-info-container')\n",
    "    for book in booklist:\n",
    "        title = book.find_all('h3', class_='books-front-meta-title')[0].text\n",
    "        author = book.find_all('span', class_='books-front-meta-authorInfo')[0].text\n",
    "        genre = book.find_all('div', class_='books-front-meta-genre')[0].text\n",
    "        rank += 1\n",
    "        print('{}. {}, {}, {}'.format(rank, title, author, genre))\n",
    "        data.append((rank,title,author,genre))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3: Geocoding (using an API) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example is how to use an API to gather data of interest. Sometimes, you will need to get an api key or access token to access the website. The website should have a developers or API section to let you know how to query the API with the appropriate parameters. This section will also detail the terms of usage and any usage limits on using the API. APIs usually follow a freemium business model. \n",
    "\n",
    "We'll show you how to geocode addresses using the Google Maps Geocoding API. Let's look at the documentation quickly.    \n",
    "https://developers.google.com/maps/documentation/geocoding/intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The documentation tells us the format looks something like this\n",
    "\n",
    "`https://maps.googleapis.com/maps/api/geocode/outputFormat?parameters`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, the documentation tells us about:\n",
    "1. Needing an API key.\n",
    "2. Format of the request needed\n",
    "2. Choosing an output format\n",
    "3. Required parameters\n",
    "4. Optional parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Starting June 2018, Google requires you to enable billing to use its Google Maps APIs. It gives you $200/month of free usage before billing starts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query String Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A url that contains a query string will contain three parts:\n",
    "1. Resource (base) URL\n",
    "2. Question Mark (?)\n",
    "3. Parameters (key=value pairs) separated by an ampersand (&)\n",
    "\n",
    "Let's look at the Google geocoding example with our own API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://maps.googleapis.com/maps/api/geocode/json?address=1600+Amphitheatre+Parkway,+Mountain+View,+CA&key=AIzaSyCrgOA4vLuYvJjGT28edRNFIuMCenhYFBs'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "apikey = <INSERT API KEY>\n",
    "url = r'https://maps.googleapis.com/maps/api/geocode/json?address=1600+Amphitheatre+Parkway,+Mountain+View,+CA&key={}'.format(apikey)\n",
    "url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break down the different pieces for this example.\n",
    "1. The resource url is `https://maps.googleapis.com/maps/api/geocode/json`\n",
    "2. The output format chosen was json\n",
    "3. `?`\n",
    "4. First required parameter is `address=1600+Amphitheatre+Parkway,+Mountain+View,+CA`\n",
    "5. `&`\n",
    "6. Second required parameter is `key=<YOUR API KEY>`\n",
    "7. No optional key/value pair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that some characters can not be part of the URL like spaces in the above example. Spaces are encoded as `+` or `%20`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now can make a `GET` request. Same as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'results': [{'address_components': [{'long_name': 'Google Building 41',\n",
       "     'short_name': 'Google Building 41',\n",
       "     'types': ['premise']},\n",
       "    {'long_name': '1600', 'short_name': '1600', 'types': ['street_number']},\n",
       "    {'long_name': 'Amphitheatre Parkway',\n",
       "     'short_name': 'Amphitheatre Pkwy',\n",
       "     'types': ['route']},\n",
       "    {'long_name': 'Mountain View',\n",
       "     'short_name': 'Mountain View',\n",
       "     'types': ['locality', 'political']},\n",
       "    {'long_name': 'Santa Clara County',\n",
       "     'short_name': 'Santa Clara County',\n",
       "     'types': ['administrative_area_level_2', 'political']},\n",
       "    {'long_name': 'California',\n",
       "     'short_name': 'CA',\n",
       "     'types': ['administrative_area_level_1', 'political']},\n",
       "    {'long_name': 'United States',\n",
       "     'short_name': 'US',\n",
       "     'types': ['country', 'political']},\n",
       "    {'long_name': '94043', 'short_name': '94043', 'types': ['postal_code']}],\n",
       "   'formatted_address': 'Google Building 41, 1600 Amphitheatre Pkwy, Mountain View, CA 94043, USA',\n",
       "   'geometry': {'bounds': {'northeast': {'lat': 37.4228775,\n",
       "      'lng': -122.085133},\n",
       "     'southwest': {'lat': 37.4221145, 'lng': -122.0860002}},\n",
       "    'location': {'lat': 37.4224082, 'lng': -122.0856086},\n",
       "    'location_type': 'ROOFTOP',\n",
       "    'viewport': {'northeast': {'lat': 37.4238449802915,\n",
       "      'lng': -122.0842176197085},\n",
       "     'southwest': {'lat': 37.4211470197085, 'lng': -122.0869155802915}}},\n",
       "   'place_id': 'ChIJxQvW8wK6j4AR3ukttGy3w2s',\n",
       "   'types': ['premise']}],\n",
       " 'status': 'OK'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = requests.get(url)\n",
    "response = R.json()\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Webscraping done! API conquered!\n",
    "\n",
    "Manually encoding strings for URLs can be a pain. Thankfully, the `requests` library takes care of all this for us if we pass a dictionary to the `params` keyword argument.\n",
    "\n",
    "First we need to construct the dictionary for the parameters and the specify the resource url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'address': '915 E Washington, Ann Arbor',\n",
    "          'key':apikey\n",
    "         }\n",
    "baseurl = 'https://maps.googleapis.com/maps/api/geocode/json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a `GET` request with the params keyword argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'results': [{'address_components': [{'long_name': '915',\n",
       "     'short_name': '915',\n",
       "     'types': ['street_number']},\n",
       "    {'long_name': 'East Washington Street',\n",
       "     'short_name': 'E Washington St',\n",
       "     'types': ['route']},\n",
       "    {'long_name': 'Burns Park',\n",
       "     'short_name': 'Burns Park',\n",
       "     'types': ['neighborhood', 'political']},\n",
       "    {'long_name': 'Ann Arbor',\n",
       "     'short_name': 'Ann Arbor',\n",
       "     'types': ['locality', 'political']},\n",
       "    {'long_name': 'Washtenaw County',\n",
       "     'short_name': 'Washtenaw County',\n",
       "     'types': ['administrative_area_level_2', 'political']},\n",
       "    {'long_name': 'Michigan',\n",
       "     'short_name': 'MI',\n",
       "     'types': ['administrative_area_level_1', 'political']},\n",
       "    {'long_name': 'United States',\n",
       "     'short_name': 'US',\n",
       "     'types': ['country', 'political']},\n",
       "    {'long_name': '48109', 'short_name': '48109', 'types': ['postal_code']},\n",
       "    {'long_name': '1070',\n",
       "     'short_name': '1070',\n",
       "     'types': ['postal_code_suffix']}],\n",
       "   'formatted_address': '915 E Washington St, Ann Arbor, MI 48109, USA',\n",
       "   'geometry': {'location': {'lat': 42.2808083, 'lng': -83.7382583},\n",
       "    'location_type': 'ROOFTOP',\n",
       "    'viewport': {'northeast': {'lat': 42.2821572802915,\n",
       "      'lng': -83.73690931970849},\n",
       "     'southwest': {'lat': 42.2794593197085, 'lng': -83.7396072802915}}},\n",
       "   'partial_match': True,\n",
       "   'place_id': 'ChIJG0N-sUGuPIgRhWJ5XDKXPt4',\n",
       "   'types': ['street_address']}],\n",
       " 'status': 'OK'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = requests.get(baseurl, params=params)\n",
    "R.raise_for_status()\n",
    "response = R.json()\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same result. And we can also spy the actual url that was sent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://maps.googleapis.com/maps/api/geocode/json?key=AIzaSyCrgOA4vLuYvJjGT28edRNFIuMCenhYFBs&address=915+E+Washington%2C+Ann+Arbor'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R.url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! Pretty simple, eh! A lot of APIs work just like this. Some, of course, are a bit more complicated. \n",
    "\n",
    "**Note:** CSCAR also has workshops on using social media APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traversing a JSON object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that we have a JSON response from the API, we need to know how to parse it for the information we are looking for. A JSON object behaves like a Python dictionary in that it consists of key-value pairs. JSON objects consist of dictionaries and lists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To look at the variables in a JSON object hierarchically, use the `keys` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['results', 'status'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access the key like you would a Python dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'address_components': [{'long_name': '915',\n",
       "    'short_name': '915',\n",
       "    'types': ['street_number']},\n",
       "   {'long_name': 'East Washington Street',\n",
       "    'short_name': 'E Washington St',\n",
       "    'types': ['route']},\n",
       "   {'long_name': 'Burns Park',\n",
       "    'short_name': 'Burns Park',\n",
       "    'types': ['neighborhood', 'political']},\n",
       "   {'long_name': 'Ann Arbor',\n",
       "    'short_name': 'Ann Arbor',\n",
       "    'types': ['locality', 'political']},\n",
       "   {'long_name': 'Washtenaw County',\n",
       "    'short_name': 'Washtenaw County',\n",
       "    'types': ['administrative_area_level_2', 'political']},\n",
       "   {'long_name': 'Michigan',\n",
       "    'short_name': 'MI',\n",
       "    'types': ['administrative_area_level_1', 'political']},\n",
       "   {'long_name': 'United States',\n",
       "    'short_name': 'US',\n",
       "    'types': ['country', 'political']},\n",
       "   {'long_name': '48109', 'short_name': '48109', 'types': ['postal_code']},\n",
       "   {'long_name': '1070',\n",
       "    'short_name': '1070',\n",
       "    'types': ['postal_code_suffix']}],\n",
       "  'formatted_address': '915 E Washington St, Ann Arbor, MI 48109, USA',\n",
       "  'geometry': {'location': {'lat': 42.2808083, 'lng': -83.7382583},\n",
       "   'location_type': 'ROOFTOP',\n",
       "   'viewport': {'northeast': {'lat': 42.2821572802915,\n",
       "     'lng': -83.73690931970849},\n",
       "    'southwest': {'lat': 42.2794593197085, 'lng': -83.7396072802915}}},\n",
       "  'partial_match': True,\n",
       "  'place_id': 'ChIJG0N-sUGuPIgRhWJ5XDKXPt4',\n",
       "  'types': ['street_address']}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['results']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Occasionally, you will encounter a `list` of key-value pairs in the hierarchy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You would access the `list` the same way as a Python list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'address_components': [{'long_name': '915',\n",
       "   'short_name': '915',\n",
       "   'types': ['street_number']},\n",
       "  {'long_name': 'East Washington Street',\n",
       "   'short_name': 'E Washington St',\n",
       "   'types': ['route']},\n",
       "  {'long_name': 'Burns Park',\n",
       "   'short_name': 'Burns Park',\n",
       "   'types': ['neighborhood', 'political']},\n",
       "  {'long_name': 'Ann Arbor',\n",
       "   'short_name': 'Ann Arbor',\n",
       "   'types': ['locality', 'political']},\n",
       "  {'long_name': 'Washtenaw County',\n",
       "   'short_name': 'Washtenaw County',\n",
       "   'types': ['administrative_area_level_2', 'political']},\n",
       "  {'long_name': 'Michigan',\n",
       "   'short_name': 'MI',\n",
       "   'types': ['administrative_area_level_1', 'political']},\n",
       "  {'long_name': 'United States',\n",
       "   'short_name': 'US',\n",
       "   'types': ['country', 'political']},\n",
       "  {'long_name': '48109', 'short_name': '48109', 'types': ['postal_code']},\n",
       "  {'long_name': '1070',\n",
       "   'short_name': '1070',\n",
       "   'types': ['postal_code_suffix']}],\n",
       " 'formatted_address': '915 E Washington St, Ann Arbor, MI 48109, USA',\n",
       " 'geometry': {'location': {'lat': 42.2808083, 'lng': -83.7382583},\n",
       "  'location_type': 'ROOFTOP',\n",
       "  'viewport': {'northeast': {'lat': 42.2821572802915,\n",
       "    'lng': -83.73690931970849},\n",
       "   'southwest': {'lat': 42.2794593197085, 'lng': -83.7396072802915}}},\n",
       " 'partial_match': True,\n",
       " 'place_id': 'ChIJG0N-sUGuPIgRhWJ5XDKXPt4',\n",
       " 'types': ['street_address']}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['results'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, there is only one element in this list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to drill deeper into the `results` key, you would repeat the process to look at available keys and so forth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['place_id', 'geometry', 'formatted_address', 'types', 'partial_match', 'address_components'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['results'][0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To arrive at the latitude coordinate, you would need the following syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.2808083"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['results'][0]['geometry']['location']['lat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: If you have a keen eye, you can just eyeball the hierarchy without needing to use the `keys` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 4: Weather Data (using an API)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of an API that doesn't follow the query string parameter format.\n",
    "\n",
    "We will be using <a href='https://darksky.net/app/'>https://darksky.net/app/</a> to gather weather data.  The developer section is at https://darksky.net/dev/. The API documentation is at https://darksky.net/dev/docs. You will need to create an account to get an API key (or you can borrow mine).\n",
    "\n",
    "**Note**: Dark Sky is a relatively simple API (part of the reason why I'm using it as an example). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather Forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "APIs usually have different endpoints depending on the data you are interested in. The documentation page shows that you can make two types of API requests. \n",
    "1. The current weather forecast for the next week (forecast request)\n",
    "2. An observed or forecast weather conditions for a date in the past or future (time machine request)\n",
    "\n",
    "**Note**: BTW, two is a relatively small number. The twitter API has over 100.\n",
    "\n",
    "Let's look at endpoint #2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The documentation shows that a forecast request takes the form of:\n",
    "\n",
    "https://api.darksky.net/forecast/[key]/[latitude],[longitude],[time]\n",
    "\n",
    "A historical weather request returns the observed weather at a given time (for many places, up to 60 years in the past)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by specifying the API key and then the GPS coordinates and timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "apikey = <INSERT API KEY>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "latitude = 42.28\n",
    "longitude = -83.74\n",
    "time = '2017-01-31T16:00:00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url = r'https://api.darksky.net/forecast/{}/{},{},{}'.format(apikey,latitude,longitude,time)\n",
    "R = requests.get(url)\n",
    "R.raise_for_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API responses consist of a JSON-formatted object (UTF-8) according to the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pastforecast = R.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Webscraping DONE!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hourly summary and temperature for that day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Overcast 22.99\n",
      "1 Foggy 23.57\n",
      "2 Foggy 24.14\n",
      "3 Foggy 24.75\n",
      "4 Foggy 25.27\n",
      "5 Foggy 25.87\n",
      "6 Foggy 26.19\n",
      "7 Overcast 26.21\n",
      "8 Overcast 26.4\n",
      "9 Overcast 27.22\n",
      "10 Overcast 28.37\n",
      "11 Overcast 29.87\n",
      "12 Overcast 30.99\n",
      "13 Overcast 32.4\n",
      "14 Overcast 32.7\n",
      "15 Overcast 32.94\n",
      "16 Overcast 32.8\n",
      "17 Overcast 32.05\n",
      "18 Overcast 31.27\n",
      "19 Overcast 31.07\n",
      "20 Overcast 31.22\n",
      "21 Overcast 31.17\n",
      "22 Mostly Cloudy 31.24\n",
      "23 Partly Cloudy 31.29\n"
     ]
    }
   ],
   "source": [
    "for i, hr in enumerate(pastforecast[\"hourly\"][\"data\"]):\n",
    "    print(i, hr['summary'], hr['temperature'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: API responses come in a variety of flavours. Some common ones are JSON, XML, and CSV format. I recommend choosing JSON over XML whenever possible. XML is a pain to work with IMO. If you do choose XML, you can use `BeautifulSoup` or `ElementTree` to parse the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Wrappers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the more popular APIs (like Twitter and Google), the open source community has probably written a Python wrapper for the API to abstract away some of the details for you. The Dark Sky API is pretty simple as you can see but someone has written a wrapper for it because of its popularity. The Python module is called `python-forecastio`. You can install it using `pip install python-forecastio`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import forecastio\n",
    "\n",
    "lon = -83.7\n",
    "lat = 42.3\n",
    "forecast = forecastio.load_forecast(apikey, lat, lon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing the data depends on the structure the developer set up which is not necessarily the same as the API. You will need to read the documentation of the module to understand the structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Partly cloudy starting in the afternoon.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast.daily().data[0].summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Google Maps Distance Matrix API, get the the distance from Ann Arbor, MI to San Diego, CA and Anchorage, AK.\n",
    "\n",
    "The documentation is located at https://developers.google.com/maps/documentation/distance-matrix/start\n",
    "\n",
    "**Tip:** Don't worry about including the API key as a parameter. For some reason, it is not needed for this API to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: POST Requests</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example was taken from the book **Web Scraping with Python** by Ryan Mitchell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This website http://pythonscraping.com/pages/files/form.html shows a basic web form. Let's look at the page source to see info related to the `post` request."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The page source contains the variable names of the two input fields which need to be submitted in the `<form>` tag. We create a dictionary to represent these fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = {'firstname':'Mister',\n",
    "        'lastname' :'Cao'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an `action` attribute associated with the `post` request. This is the url where the `post` is being sent. This is a **relative** path to the current url. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello there, Mister Cao!'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = requests.post(\"http://pythonscraping.com/pages/files/processing.php\", data=data)\n",
    "R.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll see in the next section a way to get at the same information through the browser's developer tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 6: Farm Equipment Crashes in Ann Arbor (data that is not visible in the page source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example is meant to illustrate how to grab data that is visible on the webpage but not in the page source. The website of interest is https://www.michigantrafficcrashfacts.org/querytool. We are interested in grabbing the gps coordinates of the crashes on the map. The crashes also has some information in a popup tooltip when you click on it.\n",
    "\n",
    "The goal is to find the URL where the GET/POST request is being sent. How do we do that? The answer lies in the reference link at the bottom of this example. Basically, you need your browser's developer tool and some detective work.  \n",
    "[SHORT OVERLUDE TO THE WEBPAGE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congrats! You can consider yourself a developer now that you can use the toolbox :)\n",
    "\n",
    "Now that we have found the URL of interest, we go back to our regularly scheduled programming (pun intended). Everything should be easy peasy moving forward. We know the url where the `post` request is being sent. There is also some data being sent with it. We will create a dictionary for that bit of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mtcf_url = r'https://www.michigantrafficcrashfacts.org/qjson'\n",
    "query = {'q':'1;0;2017,2016,2015,2014,2013,2012,2011,2010,2009,2008,2007,2006,2005,2004;c8189;0,42:1',\n",
    "        'v':'map',\n",
    "        'p':'13,42.264652,-83.729607,0.3'}   \n",
    "R = requests.post(mtcf_url, data=query)\n",
    "R.raise_for_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab json response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'crash.id': '2015156119',\n",
       "  'crash_day': 14,\n",
       "  'crash_month': 'July',\n",
       "  'crash_time_of_day': '5:00 PM - 6:00 PM',\n",
       "  'crash_worst_injury': 'Possible injury (C)',\n",
       "  'crash_year': '2015',\n",
       "  'gps_x_coordinate': -83.762084436151,\n",
       "  'gps_y_coordinate': 42.2444715503,\n",
       "  'person_id': '8',\n",
       "  'seg_crnt': 10003762,\n",
       "  'seg_orig': 0,\n",
       "  'vehicle_id': '3'},\n",
       " '1': {'crash.id': '200578099',\n",
       "  'crash_day': 9,\n",
       "  'crash_month': 'February',\n",
       "  'crash_time_of_day': '1:00 PM - 2:00 PM',\n",
       "  'crash_worst_injury': 'No injury (O)',\n",
       "  'crash_year': '2005',\n",
       "  'gps_x_coordinate': -83.68753,\n",
       "  'gps_y_coordinate': 42.24527,\n",
       "  'person_id': '3',\n",
       "  'seg_crnt': 4839525,\n",
       "  'seg_orig': 0,\n",
       "  'vehicle_id': '3'},\n",
       " '2': {'crash.id': '2015113037',\n",
       "  'crash_day': 26,\n",
       "  'crash_month': 'February',\n",
       "  'crash_time_of_day': '8:00 AM - 9:00 AM',\n",
       "  'crash_worst_injury': 'No injury (O)',\n",
       "  'crash_year': '2015',\n",
       "  'gps_x_coordinate': -83.78405039994,\n",
       "  'gps_y_coordinate': 42.281289282301,\n",
       "  'person_id': '2',\n",
       "  'seg_crnt': 4818100,\n",
       "  'seg_orig': 0,\n",
       "  'vehicle_id': '2'},\n",
       " '3': {'crash.id': '2011112810',\n",
       "  'crash_day': 23,\n",
       "  'crash_month': 'May',\n",
       "  'crash_time_of_day': '7:00 AM - 8:00 AM',\n",
       "  'crash_worst_injury': 'No injury (O)',\n",
       "  'crash_year': '2011',\n",
       "  'gps_x_coordinate': -83.720369104399,\n",
       "  'gps_y_coordinate': 42.261075358399,\n",
       "  'person_id': '2',\n",
       "  'seg_crnt': 4827523,\n",
       "  'seg_orig': 0,\n",
       "  'vehicle_id': '2'},\n",
       " 'errors': [],\n",
       " 'headers': {'crash.id': 'Crash ID',\n",
       "  'crash_day': 'Crash Day',\n",
       "  'crash_month': 'Crash Month',\n",
       "  'crash_time_of_day': 'Crash Hour',\n",
       "  'crash_worst_injury': 'Crash Worst Injury',\n",
       "  'crash_year': 'Crash Year',\n",
       "  'gps_x_coordinate': 'Crash Lat',\n",
       "  'gps_y_coordinate': 'Crash Long',\n",
       "  'person_id': 'Person Count',\n",
       "  'seg_crnt': 'Road Segment',\n",
       "  'seg_orig': 'Orig Segment',\n",
       "  'vehicle_id': 'Unit Count'},\n",
       " 'meta': [],\n",
       " 'warnings': []}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crash_data = R.json()\n",
    "crash_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Webscraping DONE!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "http://www.gregreda.com/2015/02/15/web-scraping-finding-the-api/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This website generates random VINs upon demand http://randomvin.com. This is probably one of the most simplest html page you will ever see (and one of the reasons I picked it)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is some example code to grab 3 VINs from the website. Supply the appropriate url to finish the code. What file format is the response?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    R = requests.get('')\n",
    "    R.raise_for_status()\n",
    "    print(R.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrying Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module is aptly name. Even though you have written valid code, sometimes it will still crash for unforseen reasons (e.g. bad network connection). This is where the `retry` behaviour becomes handy. You will need to install the module first via `pip install retrying`. Documentation is at https://pypi.python.org/pypi/retrying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from retrying import retry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Retry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a simple case of how to use `retry`. First step is to put your code of interest in a function. This non-sensical function has a 90% chance of failing when run because of the `assert` statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-12a8914dbdfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0mB\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mis_B_equal_to_lucky7\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'this has a 10% chance of printing'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-12a8914dbdfe>\u001b[0m in \u001b[0;36mis_B_equal_to_lucky7\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[1;32massert\u001b[0m \u001b[0mB\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mis_B_equal_to_lucky7\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def is_B_equal_to_lucky7():\n",
    "    B = random.randint(1, 10)\n",
    "    print(B)\n",
    "    assert B == 7\n",
    "\n",
    "is_B_equal_to_lucky7()\n",
    "print('this has a 10% chance of printing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add the `retry` behavior by adding an @ decorator at the beginning of the function. That's it! Pretty simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "9\n",
      "5\n",
      "7\n",
      "this will ALWAYS print\n"
     ]
    }
   ],
   "source": [
    "@retry()\n",
    "def is_B_equal_to_lucky7():\n",
    "    B = random.randint(1, 10)\n",
    "    print(B)\n",
    "    assert B == 7\n",
    "    \n",
    "is_B_equal_to_lucky7()\n",
    "print('this will ALWAYS print')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also add an argument `wait_fixed` in milliseconds to specify how long to wait between retries. Good practice so you don't have to bombard the server with constant requests during a failed connection during webscraping. Gmail does an exponential version of this when it loses the network connection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retry on specific or general exceptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw the function fail earlier because of an `AssertionError`. We can tell `retry` to only retry when certain exceptions occur.  This requires using the argument `retry_on_exception` and passing it the name of a function. The function will return either `True` or `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "10\n",
      "7\n",
      "Lucky 7\n"
     ]
    }
   ],
   "source": [
    "def checkForSpecificError(exception):\n",
    "    return isinstance(exception, AssertionError)\n",
    "\n",
    "@retry(retry_on_exception=checkForSpecificError, wait_fixed=500)\n",
    "def is_it_lucky7():\n",
    "    B = random.randint(1, 10)\n",
    "    print(B)\n",
    "    assert B == 7\n",
    "\n",
    "is_it_lucky7()\n",
    "print(\"Lucky 7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we had changed the last line in the function to `assert C == 7`, then the retry behaviour will not kick in because the function returns a `NameError`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retry on return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You don't necessarily need to have a program error to invoke the `retry` behaviour. You can use the `return` value to decide. This requires using the argument `retry_on_result` and passing it the name of a function. The function will return either `True` or `False`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n",
      "7\n",
      "Did I find a 7?\n"
     ]
    }
   ],
   "source": [
    "def checkReturnValue(value):\n",
    "    return value is True\n",
    "\n",
    "# This function will never crash but we can still use retry\n",
    "@retry(retry_on_result=checkReturnValue, wait_fixed=300)\n",
    "def main():\n",
    "    B = random.randint(1, 10)\n",
    "    print(B)\n",
    "    try:\n",
    "        assert B == 7\n",
    "        return None\n",
    "    except AssertionError:\n",
    "        return True\n",
    "\n",
    "main()\n",
    "print('Did I find a 7?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other arguments of interest to `retry` which you can use are:  \n",
    "- stop_max_attempt_number\n",
    "- stop_max_delay\n",
    "- wait_random_min\n",
    "- wait_random_max\n",
    "- wait_exponential_multiplier\n",
    "- wait_exponential_max`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: You could implement the retry behavior without this module. You can use a `while` loop in some combination with `try` and `except` too. I don't recommend it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the `retry` module to this flaky code for the Dark Sky API to try 5 times waiting one second in between attempts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_weather_from_Eastern_hemisphere(apikey):\n",
    "    lon = random.randint(0,400)\n",
    "    lat = random.randint(0,200)\n",
    "    print('{} deg E, {} deg N'.format(lon,lat))\n",
    "    R = requests.get('https://api.darksky.net/forecast/{}/{},{}'.format(apikey,lat,lon))\n",
    "    R.raise_for_status()\n",
    "    return (lon,lat,R.json())\n",
    "    \n",
    "apikey = <INSERT API KEY>\n",
    "lon, lat, forecast = get_weather_from_Eastern_hemisphere(apikey)\n",
    "print(forecast[\"daily\"][\"data\"][0]['summary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://goo.gl/forms/Ym3hbKu45nzQ2puv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cURL to Python Requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cURL is a command line tool for getting or sending files using URL syntax. You can always get the cURL command from the developer tool. This usually also includes *cookies and headers*. While Python can't use it directly, you can convert it to a Python requests syntax. Googling *curl to python requests* will bring you to this page https://curl.trillworks.com/. You can paste the curl code and it will return the equivalent Python code for you. Python does have a module that is suppose to do this for you but I haven't gotten it to work yet. Some modules are `uncurl, runcurl, curl_to_requests` but they support Python2 only.\n",
    "\n",
    "For example, here is what is returned for the curl cmd from http://random.vin.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "cookies = {\n",
    "    '_ga': 'GA1.2.690271399.1483585728',\n",
    "    '_gat': '1',\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    'Accept-Encoding': 'gzip, deflate, sdch',\n",
    "    'Accept-Language': 'en-US,en;q=0.8',\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36',\n",
    "    'Accept': '*/*',\n",
    "    'Referer': 'http://randomvin.com/',\n",
    "    'Connection': 'keep-alive',\n",
    "}\n",
    "\n",
    "requests.get('http://randomvin.com/getvin.php?type=real', headers=headers, cookies=cookies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robots.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also known as the robot exclusion standard, *robots.txt* is a standard used by website to communicate to web crawlers, scrapers etc. The robots.txt is a file that is used to communicate which parts of the website is allowed or disallowed to be scraped. You will find the robots.txt file in the root directory of the website. For the english version of wikipedia, it is located at https://en.wikipedia.org/robots.txt.  \n",
    "\n",
    "The complement to *robots.txt* is the *sitemap* which is an XML file that lists the URLs for a site. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
