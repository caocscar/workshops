{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copying and pasting is great. You should definitely use it if it's the simplest way. But if you don't want to copy and paste 10 webpages into Excel or if you have some time to kill, then web scraping is the answer or time sink you've been looking for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing the python modules that we will need to do web scraping. We will be using `requests` to fetch html pages and `BeautifulSoup` to parse the html page. `pandas` will be used for data manipulation. The `pd.options.display` lines are for formatting purposes when printing out results in `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_rows = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: Wikipedia Page (HTML Table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by opening the <a href='https://en.wikipedia.org/wiki/List_of_Michigan_locations_by_per_capita_income'>website of interest</a> in a browser. We can see that it looks nicely formatted like a table. We start with passing the website of interest to the `requests.get` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = r'https://en.wikipedia.org/wiki/List_of_Michigan_locations_by_per_capita_income'\n",
    "R = requests.get(url)\n",
    "R.raise_for_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Without the `R.raise_for_status()` line, bad urls will fail silently which is probably not what you want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use `BeautifulSoup` to parse the contents of the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(R.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I like to use the browser's developer tool to do the detective work of figuring out where the data resides (*right click -> Inspect*). In this example, the data of interest resides in a html table (makes life easier)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the data of interest resides in a table tag &lt;table&gt;. To grab everything between the table tags, we use the `find_all` method (one of many options but probably the only one you need and the one you will use most often)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = soup.find_all('table')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`find_all` returns a list of matches. We can use the `len` function to see how many matches came back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the contents of the table using the `text` method. It will be a formatting mess but that's okay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This article is part of a series onIncome in theUnited States of America\\nTopics\\nHousehold\\nPersonal\\nAffluence\\nSocial class\\nIncome inequality\\ngender pay gap\\nethnic wage gap\\n\\nLists by income\\nStates (by equality (Gini))\\nCounties (highest\\xa0/ lowest)\\nLocations (lowest)\\nMetropolitan statistical areas\\nUrban areas\\nZIP Code Tabulation Areas\\n\\n United States portalvte'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nRank\\n\\nCounty\\n\\nPer capitaincome\\n\\nMedianhouseholdincome\\n\\nMedianfamilyincome\\n\\nPopulation\\n\\nNumber ofhouseholds\\n\\n\\n1\\n\\nOakland\\n\\n$56,138\\n\\n$85,991\\n\\n$94,783\\n\\n1,202,362\\n\\n483,698\\n\\n\\n2\\n\\nLeelanau\\n\\n$32,194\\n\\n$56,527\\n\\n$65,342\\n\\n21,708\\n\\n9,255\\n\\n\\n3\\n\\nLivingston\\n\\n$31,609\\n\\n$72,129\\n\\n$82,637\\n\\n180,967\\n\\n67,380\\n\\n\\n4\\n\\nWashtenaw\\n\\n$31,316\\n\\n$59,065\\n\\n$82,184\\n\\n344,791\\n\\n137,193\\n\\n\\n5\\n\\nCharlevoix\\n\\n$28,403\\n\\n$48,704\\n\\n$57,022\\n\\n25,949\\n\\n10,882\\n\\n\\n6\\n\\nMidland\\n\\n$28,363\\n\\n$51,103\\n\\n$63,299\\n\\n83,629\\n\\n33,437\\n\\n\\n7\\n\\nEmmet\\n\\n$28,308\\n\\n$49,235\\n\\n$61,600\\n\\n32,694\\n\\n13,601\\n\\n\\n\\n\\nUnited States\\n\\n$27,334\\n\\n$51,914\\n\\n$62,982\\n\\n308,745,538\\n\\n116,716,292\\n\\n\\n8\\n\\nClinton\\n\\n$27,223\\n\\n$58,016\\n\\n$69,611\\n\\n75,382\\n\\n28,766\\n\\n\\n9\\n\\nGrand Traverse\\n\\n$27,091\\n\\n$50,647\\n\\n$61,780\\n\\n86,986\\n\\n35,328\\n\\n\\n10\\n\\nMacomb\\n\\n$26,524\\n\\n$53,996\\n\\n$67,423\\n\\n840,978\\n\\n331,667\\n\\n\\n11\\n\\nEaton\\n\\n$25,963\\n\\n$54,885\\n\\n$66,788\\n\\n107,759\\n\\n43,494\\n\\n\\n12\\n\\nMonroe\\n\\n$25,520\\n\\n$55,366\\n\\n$66,549\\n\\n152,021\\n\\n58,230\\n\\n\\n13\\n\\nKalamazoo\\n\\n$25,138\\n\\n$44,794\\n\\n$61,622\\n\\n250,331\\n\\n100,610\\n\\n\\n\\n\\nMichigan\\n\\n$25,135\\n\\n$48,432\\n\\n$60,341\\n\\n9,883,640\\n\\n3,872,508\\n\\n\\n14\\n\\nLapeer\\n\\n$25,110\\n\\n$55,005\\n\\n$63,061\\n\\n88,319\\n\\n32,776\\n\\n\\n15\\n\\nOttawa\\n\\n$25,045\\n\\n$55,095\\n\\n$65,474\\n\\n263,801\\n\\n93,775\\n\\n\\n16\\n\\nKent\\n\\n$24,791\\n\\n$49,532\\n\\n$61,097\\n\\n602,622\\n\\n227,239\\n\\n\\n17\\n\\nBarry\\n\\n$24,493\\n\\n$51,869\\n\\n$61,202\\n\\n59,173\\n\\n22,551\\n\\n\\n18\\n\\nBerrien\\n\\n$24,025\\n\\n$42,625\\n\\n$54,751\\n\\n156,813\\n\\n63,054\\n\\n\\n19\\n\\nAntrim\\n\\n$23,912\\n\\n$43,123\\n\\n$50,424\\n\\n23,580\\n\\n9,890\\n\\n\\n20\\n\\nIngham\\n\\n$23,883\\n\\n$45,808\\n\\n$61,680\\n\\n280,895\\n\\n111,162\\n\\n\\n21\\n\\nDickinson\\n\\n$23,854\\n\\n$42,586\\n\\n$54,053\\n\\n26,168\\n\\n11,359\\n\\n\\n22\\n\\nSt. Clair\\n\\n$23,828\\n\\n$49,120\\n\\n$59,969\\n\\n163,040\\n\\n63,841\\n\\n\\n23\\n\\nBenzie\\n\\n$23,649\\n\\n$44,718\\n\\n$53,250\\n\\n17,525\\n\\n7,298\\n\\n\\n24\\n\\nMarquette\\n\\n$23,347\\n\\n$45,130\\n\\n$61,798\\n\\n67,077\\n\\n27,538\\n\\n\\n25\\n\\nAllegan\\n\\n$23,108\\n\\n$50,240\\n\\n$57,831\\n\\n111,408\\n\\n42,018\\n\\n\\n26\\n\\nBay\\n\\n$23,049\\n\\n$44,659\\n\\n$53,824\\n\\n107,771\\n\\n44,603\\n\\n\\n27\\n\\nCheboygan\\n\\n$23,038\\n\\n$37,903\\n\\n$45,769\\n\\n26,152\\n\\n11,133\\n\\n\\n28\\n\\nCass\\n\\n$22,698\\n\\n$45,177\\n\\n$54,813\\n\\n52,293\\n\\n20,604\\n\\n\\n29\\n\\nOtsego\\n\\n$22,568\\n\\n$45,531\\n\\n$54,110\\n\\n24,164\\n\\n9,756\\n\\n\\n30\\n\\nLenawee\\n\\n$22,529\\n\\n$48,618\\n\\n$60,028\\n\\n99,892\\n\\n37,514\\n\\n\\n31\\n\\nGenesee\\n\\n$22,458\\n\\n$43,483\\n\\n$54,072\\n\\n425,790\\n\\n169,202\\n\\n\\n32\\n\\nMackinac\\n\\n$22,170\\n\\n$39,339\\n\\n$51,376\\n\\n11,113\\n\\n5,024\\n\\n\\n33\\n\\nCalhoun\\n\\n$22,166\\n\\n$42,568\\n\\n$52,533\\n\\n136,146\\n\\n54,016\\n\\n\\n34\\n\\nWayne\\n\\n$22,125\\n\\n$42,241\\n\\n$52,946\\n\\n1,820,584\\n\\n702,749\\n\\n\\n35\\n\\nHuron\\n\\n$22,098\\n\\n$40,038\\n\\n$49,444\\n\\n33,118\\n\\n14,348\\n\\n\\n36\\n\\nDelta\\n\\n$22,064\\n\\n$41,951\\n\\n$51,442\\n\\n37,069\\n\\n15,992\\n\\n\\n37\\n\\nVan Buren\\n\\n$22,002\\n\\n$44,435\\n\\n$54,499\\n\\n76,258\\n\\n28,928\\n\\n\\n38\\n\\nJackson\\n\\n$21,947\\n\\n$46,117\\n\\n$56,314\\n\\n160,248\\n\\n60,771\\n\\n\\n39\\n\\nShiawassee\\n\\n$21,869\\n\\n$46,453\\n\\n$54,363\\n\\n70,648\\n\\n27,481\\n\\n\\n40\\n\\nMason\\n\\n$21,760\\n\\n$40,039\\n\\n$49,131\\n\\n28,705\\n\\n11,940\\n\\n\\n41\\n\\nSaginaw\\n\\n$21,662\\n\\n$42,954\\n\\n$53,171\\n\\n200,169\\n\\n79,011\\n\\n\\n42\\n\\nMenominee\\n\\n$21,624\\n\\n$41,332\\n\\n$49,394\\n\\n24,029\\n\\n10,474\\n\\n\\n43\\n\\nManistee\\n\\n$21,612\\n\\n$40,853\\n\\n$50,101\\n\\n24,733\\n\\n10,308\\n\\n\\n44\\n\\nOntonagon\\n\\n$21,448\\n\\n$35,269\\n\\n$47,330\\n\\n6,780\\n\\n3,258\\n\\n\\n45\\n\\nKeweenaw\\n\\n$21,307\\n\\n$38,872\\n\\n$46,414\\n\\n2,156\\n\\n1,013\\n\\n\\n46\\n\\nAlpena\\n\\n$21,140\\n\\n$36,695\\n\\n$47,256\\n\\n29,598\\n\\n12,791\\n\\n\\n47\\n\\nCrawford\\n\\n$21,002\\n\\n$39,665\\n\\n$45,362\\n\\n14,074\\n\\n6,016\\n\\n\\n48\\n\\nNewaygo\\n\\n$20,870\\n\\n$43,218\\n\\n$49,499\\n\\n48,460\\n\\n18,406\\n\\n\\n49\\n\\nPresque Isle\\n\\n$20,870\\n\\n$37,383\\n\\n$43,797\\n\\n13,376\\n\\n5,982\\n\\n\\n50\\n\\nGladwin\\n\\n$20,571\\n\\n$37,936\\n\\n$44,427\\n\\n25,692\\n\\n10,753\\n\\n\\n51\\n\\nIosco\\n\\n$20,513\\n\\n$36,861\\n\\n$44,175\\n\\n25,887\\n\\n11,757\\n\\n\\n52\\n\\nSchoolcraft\\n\\n$20,455\\n\\n$36,925\\n\\n$48,141\\n\\n8,485\\n\\n3,759\\n\\n\\n53\\n\\nChippewa\\n\\n$20,309\\n\\n$40,194\\n\\n$54,066\\n\\n38,520\\n\\n14,329\\n\\n\\n54\\n\\nRoscommon\\n\\n$20,194\\n\\n$33,542\\n\\n$40,015\\n\\n24,449\\n\\n11,433\\n\\n\\n55\\n\\nSt. Joseph\\n\\n$20,192\\n\\n$44,392\\n\\n$52,586\\n\\n61,295\\n\\n23,244\\n\\n\\n56\\n\\nHillsdale\\n\\n$20,006\\n\\n$42,989\\n\\n$50,546\\n\\n46,688\\n\\n17,792\\n\\n\\n57\\n\\nIron\\n\\n$19,986\\n\\n$33,734\\n\\n$44,560\\n\\n11,817\\n\\n5,577\\n\\n\\n58\\n\\nWexford\\n\\n$19,952\\n\\n$39,997\\n\\n$46,659\\n\\n32,735\\n\\n13,021\\n\\n\\n59\\n\\nTuscola\\n\\n$19,937\\n\\n$42,198\\n\\n$50,262\\n\\n55,729\\n\\n21,590\\n\\n\\n60\\n\\nGogebic\\n\\n$19,933\\n\\n$33,673\\n\\n$45,182\\n\\n16,427\\n\\n7,037\\n\\n\\n61\\n\\nAlcona\\n\\n$19,904\\n\\n$34,858\\n\\n$43,482\\n\\n10,942\\n\\n5,089\\n\\n\\n62\\n\\nAlger\\n\\n$19,858\\n\\n$38,262\\n\\n$47,548\\n\\n9,601\\n\\n3,898\\n\\n\\n63\\n\\nKalkaska\\n\\n$19,770\\n\\n$39,350\\n\\n$45,417\\n\\n17,153\\n\\n6,962\\n\\n\\n64\\n\\nMuskegon\\n\\n$19,719\\n\\n$40,670\\n\\n$50,101\\n\\n172,188\\n\\n65,616\\n\\n\\n65\\n\\nSanilac\\n\\n$19,645\\n\\n$40,818\\n\\n$49,005\\n\\n43,114\\n\\n17,132\\n\\n\\n66\\n\\nMissaukee\\n\\n$19,560\\n\\n$40,376\\n\\n$46,371\\n\\n14,849\\n\\n5,843\\n\\n\\n67\\n\\nIonia\\n\\n$19,386\\n\\n$46,454\\n\\n$54,595\\n\\n63,905\\n\\n22,144\\n\\n\\n68\\n\\nBaraga\\n\\n$19,107\\n\\n$40,541\\n\\n$50,549\\n\\n8,860\\n\\n3,444\\n\\n\\n69\\n\\nMontmorency\\n\\n$19,102\\n\\n$34,447\\n\\n$41,230\\n\\n9,765\\n\\n4,416\\n\\n\\n70\\n\\nArenac\\n\\n$19,073\\n\\n$36,689\\n\\n$45,376\\n\\n15,899\\n\\n6,701\\n\\n\\n71\\n\\nBranch\\n\\n$19,049\\n\\n$42,133\\n\\n$50,931\\n\\n45,248\\n\\n16,419\\n\\n\\n72\\n\\nMecosta\\n\\n$18,745\\n\\n$35,887\\n\\n$48,145\\n\\n42,798\\n\\n16,101\\n\\n\\n73\\n\\nMontcalm\\n\\n$18,569\\n\\n$39,775\\n\\n$46,673\\n\\n63,342\\n\\n23,432\\n\\n\\n74\\n\\nOscoda\\n\\n$18,524\\n\\n$32,346\\n\\n$39,335\\n\\n8,640\\n\\n3,772\\n\\n\\n75\\n\\nIsabella\\n\\n$18,510\\n\\n$36,880\\n\\n$55,183\\n\\n70,311\\n\\n25,586\\n\\n\\n76\\n\\nClare\\n\\n$18,491\\n\\n$34,399\\n\\n$42,519\\n\\n30,926\\n\\n12,966\\n\\n\\n77\\n\\nOceana\\n\\n$18,402\\n\\n$39,543\\n\\n$46,424\\n\\n26,570\\n\\n10,174\\n\\n\\n78\\n\\nGratiot\\n\\n$18,388\\n\\n$40,114\\n\\n$49,989\\n\\n42,476\\n\\n14,852\\n\\n\\n79\\n\\nOgemaw\\n\\n$18,321\\n\\n$35,968\\n\\n$41,810\\n\\n21,699\\n\\n9,283\\n\\n\\n80\\n\\nHoughton\\n\\n$18,267\\n\\n$34,174\\n\\n$46,819\\n\\n36,628\\n\\n14,232\\n\\n\\n81\\n\\nOsceola\\n\\n$17,861\\n\\n$38,341\\n\\n$44,613\\n\\n23,528\\n\\n9,222\\n\\n\\n82\\n\\nLuce\\n\\n$17,195\\n\\n$40,041\\n\\n$46,510\\n\\n6,631\\n\\n2,412\\n\\n\\n83\\n\\nLake\\n\\n$16,084\\n\\n$31,205\\n\\n$38,996\\n\\n11,539\\n\\n5,158\\n\\n'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables[1].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like this is the table we want. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A better way to find the table of interest is to pass in extra search terms to the `find_all` method after using the developer tool to find searchable attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables = soup.find_all('table', class_=\"wikitable sortable\")\n",
    "len(tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get one result now instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = tables[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data resides in a html table standard cell tag `<td>` within a table row tag `<tr>`. We use `find_all` to look for all the table row tags within the table tag `<table>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_rows = table.find_all('tr')\n",
    "len(table_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now see that there are a lot of matches for that tag, as expected. It's close to the total number of countries. Let's look at the first few entries of `table_rows`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tr valign=\"bottom\">\n",
       "<th>Rank\n",
       "</th>\n",
       "<th>County\n",
       "</th>\n",
       "<th>Per capita<br/>income\n",
       "</th>\n",
       "<th>Median<br/>household<br/>income\n",
       "</th>\n",
       "<th>Median<br/>family<br/>income\n",
       "</th>\n",
       "<th>Population\n",
       "</th>\n",
       "<th>Number of<br/>households\n",
       "</th></tr>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_rows[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the header row. The `<th>` tag also gives it away, fyi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tr>\n",
       "<td>1\n",
       "</td>\n",
       "<td><a href=\"/wiki/Oakland_County,_Michigan\" title=\"Oakland County, Michigan\">Oakland</a>\n",
       "</td>\n",
       "<td>$56,138\n",
       "</td>\n",
       "<td>$85,991\n",
       "</td>\n",
       "<td>$94,783\n",
       "</td>\n",
       "<td>1,202,362\n",
       "</td>\n",
       "<td>483,698\n",
       "</td></tr>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_rows[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its the row data for the __first county__. \n",
    "\n",
    "We will use a nested `for` loop to go through the list of table rows. The inner `for` loop will go through each `<td>` tag appending the text to a list. We will grab all the data in the tags regardless of whether we want to keep them for now. \n",
    "\n",
    "We have two lists in the `for` loop. `row` will contain a list of the each `td` tag in a table row. Once the row is iterated through, we will convert it to a `pandas` dataframe. `list_df` will contain a list of those dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_df = []\n",
    "for row in table_rows:\n",
    "    table_cells = row.find_all('td')\n",
    "    row = []\n",
    "    for cell in table_cells:\n",
    "        row.append(cell.text)    \n",
    "    list_df.append(pd.DataFrame(row).transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take the list of dataframes and concatenate them together into one dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat(list_df, ignore_index=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the first 5 rows of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1\\n</td>\n",
       "      <td>Oakland\\n</td>\n",
       "      <td>$56,138\\n</td>\n",
       "      <td>$85,991\\n</td>\n",
       "      <td>$94,783\\n</td>\n",
       "      <td>1,202,362\\n</td>\n",
       "      <td>483,698\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2\\n</td>\n",
       "      <td>Leelanau\\n</td>\n",
       "      <td>$32,194\\n</td>\n",
       "      <td>$56,527\\n</td>\n",
       "      <td>$65,342\\n</td>\n",
       "      <td>21,708\\n</td>\n",
       "      <td>9,255\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3\\n</td>\n",
       "      <td>Livingston\\n</td>\n",
       "      <td>$31,609\\n</td>\n",
       "      <td>$72,129\\n</td>\n",
       "      <td>$82,637\\n</td>\n",
       "      <td>180,967\\n</td>\n",
       "      <td>67,380\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4\\n</td>\n",
       "      <td>Washtenaw\\n</td>\n",
       "      <td>$31,316\\n</td>\n",
       "      <td>$59,065\\n</td>\n",
       "      <td>$82,184\\n</td>\n",
       "      <td>344,791\\n</td>\n",
       "      <td>137,193\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5\\n</td>\n",
       "      <td>Charlevoix\\n</td>\n",
       "      <td>$28,403\\n</td>\n",
       "      <td>$48,704\\n</td>\n",
       "      <td>$57,022\\n</td>\n",
       "      <td>25,949\\n</td>\n",
       "      <td>10,882\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0             1          2          3          4            5          6\n",
       "0  1\\n     Oakland\\n  $56,138\\n  $85,991\\n  $94,783\\n  1,202,362\\n  483,698\\n\n",
       "1  2\\n    Leelanau\\n  $32,194\\n  $56,527\\n  $65,342\\n     21,708\\n    9,255\\n\n",
       "2  3\\n  Livingston\\n  $31,609\\n  $72,129\\n  $82,637\\n    180,967\\n   67,380\\n\n",
       "3  4\\n   Washtenaw\\n  $31,316\\n  $59,065\\n  $82,184\\n    344,791\\n  137,193\\n\n",
       "4  5\\n  Charlevoix\\n  $28,403\\n  $48,704\\n  $57,022\\n     25,949\\n   10,882\\n"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We didn't get the header row because it was contained in `<th>` tags and not `<td>` tags. We use the same type of `for` loop to extract the text from the table headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = table_rows[0].find_all('th')\n",
    "columns = []\n",
    "for header in headers:\n",
    "    columns.append(header.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the column headers of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>County</th>\n",
       "      <th>Per capitaincome</th>\n",
       "      <th>Medianhouseholdincome</th>\n",
       "      <th>Medianfamilyincome</th>\n",
       "      <th>Population</th>\n",
       "      <th>Number ofhouseholds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1\\n</td>\n",
       "      <td>Oakland\\n</td>\n",
       "      <td>$56,138\\n</td>\n",
       "      <td>$85,991\\n</td>\n",
       "      <td>$94,783\\n</td>\n",
       "      <td>1,202,362\\n</td>\n",
       "      <td>483,698\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2\\n</td>\n",
       "      <td>Leelanau\\n</td>\n",
       "      <td>$32,194\\n</td>\n",
       "      <td>$56,527\\n</td>\n",
       "      <td>$65,342\\n</td>\n",
       "      <td>21,708\\n</td>\n",
       "      <td>9,255\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3\\n</td>\n",
       "      <td>Livingston\\n</td>\n",
       "      <td>$31,609\\n</td>\n",
       "      <td>$72,129\\n</td>\n",
       "      <td>$82,637\\n</td>\n",
       "      <td>180,967\\n</td>\n",
       "      <td>67,380\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4\\n</td>\n",
       "      <td>Washtenaw\\n</td>\n",
       "      <td>$31,316\\n</td>\n",
       "      <td>$59,065\\n</td>\n",
       "      <td>$82,184\\n</td>\n",
       "      <td>344,791\\n</td>\n",
       "      <td>137,193\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5\\n</td>\n",
       "      <td>Charlevoix\\n</td>\n",
       "      <td>$28,403\\n</td>\n",
       "      <td>$48,704\\n</td>\n",
       "      <td>$57,022\\n</td>\n",
       "      <td>25,949\\n</td>\n",
       "      <td>10,882\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rank\\n      County\\n Per capitaincome\\n Medianhouseholdincome\\n  \\\n",
       "0    1\\n     Oakland\\n          $56,138\\n               $85,991\\n   \n",
       "1    2\\n    Leelanau\\n          $32,194\\n               $56,527\\n   \n",
       "2    3\\n  Livingston\\n          $31,609\\n               $72,129\\n   \n",
       "3    4\\n   Washtenaw\\n          $31,316\\n               $59,065\\n   \n",
       "4    5\\n  Charlevoix\\n          $28,403\\n               $48,704\\n   \n",
       "\n",
       "  Medianfamilyincome\\n Population\\n Number ofhouseholds\\n  \n",
       "0            $94,783\\n  1,202,362\\n             483,698\\n  \n",
       "1            $65,342\\n     21,708\\n               9,255\\n  \n",
       "2            $82,637\\n    180,967\\n              67,380\\n  \n",
       "3            $82,184\\n    344,791\\n             137,193\\n  \n",
       "4            $57,022\\n     25,949\\n              10,882\\n  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns = columns\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have all the data of interest. __Webscraping DONE!__ If you want to do some data cleanup and management, this is where knowledge of `pandas` becomes useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the data to a txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('micounties_income.txt', sep='|', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at the text file, there is some more data cleanup we could have done but I'm not here to teach you how to do that with `pandas` (although we do have workshops to do just that)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pandas` Approach to HTML Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pandas `read_html` method can read in HTML Tables (and only HTML Tables). It uses `BeautifulSoup` under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tables = pd.read_html(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: If you get an `ImportError: html5lib not found, please install it` message, you will need to install it via `conda install html5lib` and you might need to restart the kernel or Juypter Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns a list of dataframes. One dataframe for each table in the html page. Recall how many tables there were. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check their contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rank</td>\n",
       "      <td>County</td>\n",
       "      <td>Per capitaincome</td>\n",
       "      <td>Medianhouseholdincome</td>\n",
       "      <td>Medianfamilyincome</td>\n",
       "      <td>Population</td>\n",
       "      <td>Number ofhouseholds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Oakland</td>\n",
       "      <td>$56,138</td>\n",
       "      <td>$85,991</td>\n",
       "      <td>$94,783</td>\n",
       "      <td>1202362</td>\n",
       "      <td>483698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Leelanau</td>\n",
       "      <td>$32,194</td>\n",
       "      <td>$56,527</td>\n",
       "      <td>$65,342</td>\n",
       "      <td>21708</td>\n",
       "      <td>9255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Livingston</td>\n",
       "      <td>$31,609</td>\n",
       "      <td>$72,129</td>\n",
       "      <td>$82,637</td>\n",
       "      <td>180967</td>\n",
       "      <td>67380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Washtenaw</td>\n",
       "      <td>$31,316</td>\n",
       "      <td>$59,065</td>\n",
       "      <td>$82,184</td>\n",
       "      <td>344791</td>\n",
       "      <td>137193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0           1                 2                      3  \\\n",
       "0  Rank      County  Per capitaincome  Medianhouseholdincome   \n",
       "1     1     Oakland           $56,138                $85,991   \n",
       "2     2    Leelanau           $32,194                $56,527   \n",
       "3     3  Livingston           $31,609                $72,129   \n",
       "4     4   Washtenaw           $31,316                $59,065   \n",
       "\n",
       "                    4           5                    6  \n",
       "0  Medianfamilyincome  Population  Number ofhouseholds  \n",
       "1             $94,783     1202362               483698  \n",
       "2             $65,342       21708                 9255  \n",
       "3             $82,637      180967                67380  \n",
       "4             $82,184      344791               137193  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_tables[1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same table contains our data of interest (as expected)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also pass tag attributes to `pandas` like we did before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tables = pd.read_html(url, attrs={'class':'wikitable sortable'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rank</td>\n",
       "      <td>County</td>\n",
       "      <td>Per capitaincome</td>\n",
       "      <td>Medianhouseholdincome</td>\n",
       "      <td>Medianfamilyincome</td>\n",
       "      <td>Population</td>\n",
       "      <td>Number ofhouseholds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Oakland</td>\n",
       "      <td>$56,138</td>\n",
       "      <td>$85,991</td>\n",
       "      <td>$94,783</td>\n",
       "      <td>1202362</td>\n",
       "      <td>483698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Leelanau</td>\n",
       "      <td>$32,194</td>\n",
       "      <td>$56,527</td>\n",
       "      <td>$65,342</td>\n",
       "      <td>21708</td>\n",
       "      <td>9255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Livingston</td>\n",
       "      <td>$31,609</td>\n",
       "      <td>$72,129</td>\n",
       "      <td>$82,637</td>\n",
       "      <td>180967</td>\n",
       "      <td>67380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Washtenaw</td>\n",
       "      <td>$31,316</td>\n",
       "      <td>$59,065</td>\n",
       "      <td>$82,184</td>\n",
       "      <td>344791</td>\n",
       "      <td>137193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0           1                 2                      3  \\\n",
       "0  Rank      County  Per capitaincome  Medianhouseholdincome   \n",
       "1     1     Oakland           $56,138                $85,991   \n",
       "2     2    Leelanau           $32,194                $56,527   \n",
       "3     3  Livingston           $31,609                $72,129   \n",
       "4     4   Washtenaw           $31,316                $59,065   \n",
       "\n",
       "                    4           5                    6  \n",
       "0  Medianfamilyincome  Population  Number ofhouseholds  \n",
       "1             $94,783     1202362               483698  \n",
       "2             $65,342       21708                 9255  \n",
       "3             $82,637      180967                67380  \n",
       "4             $82,184      344791               137193  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_tables[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This leaves us at a similiar point that we encountered earlier in the example. `pandas` has basically done the web scraping for us and left us with the data cleanup and wrangling. You should always expect to do some data manipulation if you use the `pd.read_html()` method or any webscraping for that matter.\n",
    "\n",
    "Q: So why did we learn a more complicated way of doing things when `pd.read_html()` can do it for you?  \n",
    "A: Because not everything resides in an HTML table and you'll need to use the same techniques to get at the data. If the data resides in a HTML table, consider yourself fortunate, use `pandas` and move on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape Serena Williams' Wikipedia page https://en.wikipedia.org/wiki/Serena_Williams for the data in the html table **Grand Slam tournament finals**  for *Singles* in the *Career Statistics* section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2: USA TODAY Best Selling Books (not in HTML Table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the website of interest is https://www.usatoday.com/life/books/best-selling/. Suppose we are interested in getting some basic information about the book list. For this example, the data of interest does not exist in a html table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with the boilerplate template of passing the website of interest to the `requests.get` method. We then use `BeautifulSoup` to parse the contents of the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = r'https://www.usatoday.com/life/books/best-selling/'\n",
    "R = requests.get(url)\n",
    "R.raise_for_status()\n",
    "soup = BeautifulSoup(R.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Navigate to the website and use the browser's developer tool to inspect items of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data seems to be residing in a `div` tag. Let's search for that and the class info and see how many matches we get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "booklist = soup.find_all('div', class_=\"front-booklist-info-container\")\n",
    "len(booklist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the text associated within each `<div>` book tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1Past TensebyLee ChildJack Reacher stumbles across the New Hampshire town where his father was born; 23rd in series \r\n",
      "Genre:General fictionDebuted:November 15 2018\n",
      "                            Buy Now\n",
      "                        \n",
      "                                    Buy Now\n",
      "                                AmazonBarnes & NobleGoogle PlayiBooksIndieboundKoboZola1Weeks Listed#1Best Week\n",
      "1 2Whose Boat Is This Boat?byThe Staff of The Late Show with Stephen ColbertSubtitle: \"Comments That Don't Help in the Aftermath of a Hurricane\"Genre:HumorDebuted:November 15 2018\n",
      "                            Buy Now\n",
      "                        \n",
      "                                    Buy Now\n",
      "                                AmazonBarnes & NobleGoogle PlayiBooksIndieboundKoboZola1Weeks Listed#2Best Week\n",
      "2 3Diary of a Wimpy Kid: The MeltdownbyJeff KinneyYouth: Greg Heffley and Rowley Jefferson's fight after school is canceled because of snow; 13th in seriesGenre:YouthDebuted:November 08 2018\n",
      "                            Buy Now\n",
      "                        \n",
      "                                    Buy Now\n",
      "                                AmazonBarnes & NobleGoogle PlayiBooksIndieboundKoboZola#1Last Week2Weeks Listed#1Best Week\n",
      "3 4Nine Perfect StrangersbyLiane MoriartyRomance writer Frances Welty checks into a remote wellness resort, where the guests soon wonder what theyâ€™ve signed on for\r\n",
      "Genre:General fictionDebuted:November 15 2018\n",
      "                            Buy Now\n",
      "                        \n",
      "                                    Buy Now\n",
      "                                AmazonBarnes & NobleGoogle PlayiBooksIndieboundKoboZola1Weeks Listed#4Best Week\n",
      "4 5HomebodybyJoanna GainesSubtitle: \"A Guide to Creating Spaces You Never Want to Leave\"Genre:Crafts/Antiques/Collectibles/GardeningDebuted:November 15 2018\n",
      "                            Buy Now\n",
      "                        \n",
      "                                    Buy Now\n",
      "                                AmazonBarnes & NobleGoogle PlayiBooksIndieboundKoboZola1Weeks Listed#5Best Week\n",
      "5 6The ReckoningbyJohn GrishamA decorated World War II vet walks into his Methodist church in Mississippi one morning in 1946 and shoots and kills his friend and pastor\r\n",
      "\r\n",
      "Genre:General fictionDebuted:November 01 2018\n",
      "                            Buy Now\n",
      "                        \n",
      "                                    Buy Now\n",
      "                                AmazonBarnes & NobleGoogle PlayiBooksIndieboundKoboZola#4Last Week3Weeks Listed#1Best Week\n",
      "6 7The Wonky DonkeybyCraig Smith; art by Katz CowleyChildren: A lovable donkey has only three legsGenre:ChildrenDebuted:October 04 2018\n",
      "                            Buy Now\n",
      "                        \n",
      "                                    Buy Now\n",
      "                                AmazonBarnes & NobleGoogle PlayiBooksIndieboundKoboZola#5Last Week7Weeks Listed#1Best Week\n",
      "7 8Dark Sacred NightbyMichael ConnellyDetectives Renee Ballard and Harry Bosch join forces in L.A. to solve the murder of a teenage prostituteGenre:General fictionDebuted:November 08 2018\n",
      "                            Buy Now\n",
      "                        \n",
      "                                    Buy Now\n",
      "                                AmazonBarnes & NobleGoogle PlayiBooksIndieboundKoboZola#2Last Week2Weeks Listed#2Best Week\n",
      "8 9Girl, Wash Your FacebyRachel HollisSubtitle: \"Stop Believing The Lies About Who You Are So You Can Become Who You Were Meant To Be\"Genre:Psychology/Self-helpDebuted:February 15 2018\n",
      "                            Buy Now\n",
      "                        \n",
      "                                    Buy Now\n",
      "                                AmazonBarnes & NobleGoogle PlayiBooksIndieboundKoboZola#8Last Week33Weeks Listed#1Best Week\n",
      "9 10Every BreathbyNicholas SparksA woman returns to her family home where she meets a safari guide from Zimbabwe summoned to America by a letter from a man claiming to be his dadGenre:General fictionDebuted:October 25 2018\n",
      "                            Buy Now\n",
      "                        \n",
      "                                    Buy Now\n",
      "                                AmazonBarnes & NobleGoogle PlayiBooksIndieboundKoboZola#7Last Week4Weeks Listed#1Best Week\n"
     ]
    }
   ],
   "source": [
    "for i, book in enumerate(booklist):\n",
    "    print(i, book.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want the title, author and genre. Let's use the browser to inspect which tags the data lies in. Then we'll use the `find_all` method to search for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Past Tense, Lee Child, Genre:General fiction\n",
      "2. Whose Boat Is This Boat?, The Staff of The Late Show with Stephen Colbert, Genre:Humor\n",
      "3. Diary of a Wimpy Kid: The Meltdown, Jeff Kinney, Genre:Youth\n",
      "4. Nine Perfect Strangers, Liane Moriarty, Genre:General fiction\n",
      "5. Homebody, Joanna Gaines, Genre:Crafts/Antiques/Collectibles/Gardening\n",
      "6. The Reckoning, John Grisham, Genre:General fiction\n",
      "7. The Wonky Donkey, Craig Smith; art by Katz Cowley, Genre:Children\n",
      "8. Dark Sacred Night, Michael Connelly, Genre:General fiction\n",
      "9. Girl, Wash Your Face, Rachel Hollis, Genre:Psychology/Self-help\n",
      "10. Every Breath, Nicholas Sparks, Genre:General fiction\n"
     ]
    }
   ],
   "source": [
    "for rank, book in enumerate(booklist, start=1):\n",
    "    title = book.find_all('h3', class_='books-front-meta-title')[0].text\n",
    "    author = book.find_all('span', class_='books-front-meta-authorInfo')[0].text\n",
    "    genre = book.find_all('div', class_='books-front-meta-genre')[0].text\n",
    "    print('{}. {}, {}, {}'.format(rank, title, author, genre))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Webscraping DONE! At least for page one. To scrape the rest of the pages, let's navigate to the other pages. Notice anything different in the url?\n",
    "\n",
    "Before: https://www.usatoday.com/life/books/best-selling/  \n",
    "After: https://www.usatoday.com/life/books/best-selling/week/2018/24/page/2/\n",
    "\n",
    "The **before url** is the webpage for the current bestseller list, page 1. The **after url** is for a specific week and page. We can use this format to scrape any page for any given week. Much more useful than the generic url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Past Tense, Lee Child, Genre:General fiction\n",
      "2. Whose Boat Is This Boat?, The Staff of The Late Show with Stephen Colbert, Genre:Humor\n",
      "3. Diary of a Wimpy Kid: The Meltdown, Jeff Kinney, Genre:Youth\n",
      "4. Nine Perfect Strangers, Liane Moriarty, Genre:General fiction\n",
      "5. Homebody, Joanna Gaines, Genre:Crafts/Antiques/Collectibles/Gardening\n",
      "6. The Reckoning, John Grisham, Genre:General fiction\n",
      "7. The Wonky Donkey, Craig Smith; art by Katz Cowley, Genre:Children\n",
      "8. Dark Sacred Night, Michael Connelly, Genre:General fiction\n",
      "9. Girl, Wash Your Face, Rachel Hollis, Genre:Psychology/Self-help\n",
      "10. Every Breath, Nicholas Sparks, Genre:General fiction\n",
      "11. Diamond Fire, Ilona Andrews, Genre:General fiction\n",
      "12. Sea of Greed, Clive Cussler, Genre:General fiction\n",
      "13. Leopard's Run, Christine Feehan, Genre:Romance\n",
      "14. You Don't Own Me, Mary Higgins Clark, Alafair Burke, Genre:General fiction\n",
      "15. Elevation, Stephen King, Genre:General fiction\n",
      "16. Heads You Win, Jeffrey Archer, Genre:General fiction\n",
      "17. Flashback, Shannon Messenger, Genre:Youth\n",
      "18. Where the Crawdads Sing, Delia Owens, Genre:General fiction\n",
      "19. Skyward, Brandon Sanderson, Genre:General fiction\n",
      "20. Cook Like a Pro, Ina Garten, Genre:Cookbooks\n",
      "21. The Hate U Give, Angie Thomas, Genre:Youth\n",
      "22. Dog Man: Lord of the Fleas, Dav Pilkey, Genre:Youth\n",
      "23. The Noel Stranger, Richard Paul Evans, Genre:General fiction\n",
      "24. The Tattooist of Auschwitz, Heather Morris, Genre:General fiction\n",
      "25. Dork Diaries: Tales from a Not-So-Happy Birthday, Rachel Renee Russell, Genre:Youth\n",
      "26. Educated, Tara Westover, Genre:Memoir\n",
      "27. The Colors of All the Cattle, Alexander McCall Smith, Genre:General fiction\n",
      "28. Medical Medium Liver Rescue, Anthony William, Genre:Diet/Health\n",
      "29. Magnolia Table, Joanna Gaines, Marah Stets, Genre:Cookbooks\n",
      "30. The Woods, Harlan Coben, Genre:Mystery\n"
     ]
    }
   ],
   "source": [
    "rank = 0\n",
    "data = []\n",
    "for page in range(1,4):    \n",
    "    url = r'http://www.usatoday.com/life/books/best-selling/week/2018/46/page/{}/'.format(page)    \n",
    "    R = requests.get(url)\n",
    "    R.raise_for_status()\n",
    "    soup = BeautifulSoup(R.content, 'html.parser')\n",
    "    # find the element of interest matching our criteria\n",
    "    booklist = soup.find_all('div', class_='front-booklist-info-container')\n",
    "    for book in booklist:\n",
    "        title = book.find_all('h3', class_='books-front-meta-title')[0].text\n",
    "        author = book.find_all('span', class_='books-front-meta-authorInfo')[0].text\n",
    "        genre = book.find_all('div', class_='books-front-meta-genre')[0].text\n",
    "        rank += 1\n",
    "        print('{}. {}, {}, {}'.format(rank, title, author, genre))\n",
    "        data.append((rank,title,author,genre))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert the data into a `pandas` dataframe with column headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Past Tense</td>\n",
       "      <td>Lee Child</td>\n",
       "      <td>Genre:General fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Whose Boat Is This Boat?</td>\n",
       "      <td>The Staff of The Late Show with Stephen Colbert</td>\n",
       "      <td>Genre:Humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Diary of a Wimpy Kid: The Meltdown</td>\n",
       "      <td>Jeff Kinney</td>\n",
       "      <td>Genre:Youth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Nine Perfect Strangers</td>\n",
       "      <td>Liane Moriarty</td>\n",
       "      <td>Genre:General fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Homebody</td>\n",
       "      <td>Joanna Gaines</td>\n",
       "      <td>Genre:Crafts/Antiques/Collectibles/Gardening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Educated</td>\n",
       "      <td>Tara Westover</td>\n",
       "      <td>Genre:Memoir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>The Colors of All the Cattle</td>\n",
       "      <td>Alexander McCall Smith</td>\n",
       "      <td>Genre:General fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Medical Medium Liver Rescue</td>\n",
       "      <td>Anthony William</td>\n",
       "      <td>Genre:Diet/Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Magnolia Table</td>\n",
       "      <td>Joanna Gaines, Marah Stets</td>\n",
       "      <td>Genre:Cookbooks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>The Woods</td>\n",
       "      <td>Harlan Coben</td>\n",
       "      <td>Genre:Mystery</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank                               title  \\\n",
       "0      1                          Past Tense   \n",
       "1      2            Whose Boat Is This Boat?   \n",
       "2      3  Diary of a Wimpy Kid: The Meltdown   \n",
       "3      4              Nine Perfect Strangers   \n",
       "4      5                            Homebody   \n",
       "..   ...                                 ...   \n",
       "25    26                            Educated   \n",
       "26    27        The Colors of All the Cattle   \n",
       "27    28         Medical Medium Liver Rescue   \n",
       "28    29                      Magnolia Table   \n",
       "29    30                           The Woods   \n",
       "\n",
       "                                             author  \\\n",
       "0                                         Lee Child   \n",
       "1   The Staff of The Late Show with Stephen Colbert   \n",
       "2                                       Jeff Kinney   \n",
       "3                                    Liane Moriarty   \n",
       "4                                     Joanna Gaines   \n",
       "..                                              ...   \n",
       "25                                    Tara Westover   \n",
       "26                           Alexander McCall Smith   \n",
       "27                                  Anthony William   \n",
       "28                       Joanna Gaines, Marah Stets   \n",
       "29                                     Harlan Coben   \n",
       "\n",
       "                                           genre  \n",
       "0                          Genre:General fiction  \n",
       "1                                    Genre:Humor  \n",
       "2                                    Genre:Youth  \n",
       "3                          Genre:General fiction  \n",
       "4   Genre:Crafts/Antiques/Collectibles/Gardening  \n",
       "..                                           ...  \n",
       "25                                  Genre:Memoir  \n",
       "26                         Genre:General fiction  \n",
       "27                             Genre:Diet/Health  \n",
       "28                               Genre:Cookbooks  \n",
       "29                                 Genre:Mystery  \n",
       "\n",
       "[30 rows x 4 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topsellers = pd.DataFrame(data, columns=['rank','title','author','genre'])\n",
    "topsellers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify the code below to scrape the entire list and add columns such as when it debuted and how long its been on the charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Past Tense, Lee Child, Genre:General fiction\n",
      "2. Whose Boat Is This Boat?, The Staff of The Late Show with Stephen Colbert, Genre:Humor\n",
      "3. Diary of a Wimpy Kid: The Meltdown, Jeff Kinney, Genre:Youth\n",
      "4. Nine Perfect Strangers, Liane Moriarty, Genre:General fiction\n",
      "5. Homebody, Joanna Gaines, Genre:Crafts/Antiques/Collectibles/Gardening\n",
      "6. The Reckoning, John Grisham, Genre:General fiction\n",
      "7. The Wonky Donkey, Craig Smith; art by Katz Cowley, Genre:Children\n",
      "8. Dark Sacred Night, Michael Connelly, Genre:General fiction\n",
      "9. Girl, Wash Your Face, Rachel Hollis, Genre:Psychology/Self-help\n",
      "10. Every Breath, Nicholas Sparks, Genre:General fiction\n",
      "11. Diamond Fire, Ilona Andrews, Genre:General fiction\n",
      "12. Sea of Greed, Clive Cussler, Genre:General fiction\n",
      "13. Leopard's Run, Christine Feehan, Genre:Romance\n",
      "14. You Don't Own Me, Mary Higgins Clark, Alafair Burke, Genre:General fiction\n",
      "15. Elevation, Stephen King, Genre:General fiction\n",
      "16. Heads You Win, Jeffrey Archer, Genre:General fiction\n",
      "17. Flashback, Shannon Messenger, Genre:Youth\n",
      "18. Where the Crawdads Sing, Delia Owens, Genre:General fiction\n",
      "19. Skyward, Brandon Sanderson, Genre:General fiction\n",
      "20. Cook Like a Pro, Ina Garten, Genre:Cookbooks\n",
      "21. The Hate U Give, Angie Thomas, Genre:Youth\n",
      "22. Dog Man: Lord of the Fleas, Dav Pilkey, Genre:Youth\n",
      "23. The Noel Stranger, Richard Paul Evans, Genre:General fiction\n",
      "24. The Tattooist of Auschwitz, Heather Morris, Genre:General fiction\n",
      "25. Dork Diaries: Tales from a Not-So-Happy Birthday, Rachel Renee Russell, Genre:Youth\n",
      "26. Educated, Tara Westover, Genre:Memoir\n",
      "27. The Colors of All the Cattle, Alexander McCall Smith, Genre:General fiction\n",
      "28. Medical Medium Liver Rescue, Anthony William, Genre:Diet/Health\n",
      "29. Magnolia Table, Joanna Gaines, Marah Stets, Genre:Cookbooks\n",
      "30. The Woods, Harlan Coben, Genre:Mystery\n"
     ]
    }
   ],
   "source": [
    "rank = 0\n",
    "data = []\n",
    "for page in range(1,4):    \n",
    "    url = r'http://www.usatoday.com/life/books/best-selling/week/2018/46/page/{}/'.format(page)    \n",
    "    R = requests.get(url)\n",
    "    R.raise_for_status()\n",
    "    soup = BeautifulSoup(R.content, 'html.parser')\n",
    "    # find the element of interest matching our criteria\n",
    "    booklist = soup.find_all('div', class_='front-booklist-info-container')\n",
    "    for book in booklist:\n",
    "        title = book.find_all('h3', class_='books-front-meta-title')[0].text\n",
    "        author = book.find_all('span', class_='books-front-meta-authorInfo')[0].text\n",
    "        genre = book.find_all('div', class_='books-front-meta-genre')[0].text\n",
    "        rank += 1\n",
    "        print('{}. {}, {}, {}'.format(rank, title, author, genre))\n",
    "        data.append((rank,title,author,genre))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3: Geocoding (using an API) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example shows how to use an API to gather data of interest. Sometimes, you will need to get an API key or access token to access the website. The website should have a developers or API section to let you know how to query the API with the appropriate parameters. This section will also detail the terms of usage and any usage limits on using the API. APIs usually follow a freemium (free for a little stuff, pay for more stuff) business model. \n",
    "\n",
    "We'll show you how to geocode addresses using the Google Maps Geocoding API. Let's look at the documentation quickly.    \n",
    "https://developers.google.com/maps/documentation/geocoding/intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The documentation tells us the format looks something like this\n",
    "\n",
    "`https://maps.googleapis.com/maps/api/geocode/outputFormat?parameters`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, the documentation tells us about:\n",
    "1. Needing an API key.\n",
    "2. Format of the request needed\n",
    "2. Choosing an output format\n",
    "3. Required parameters\n",
    "4. Optional parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Starting June 2018, Google requires you to enable billing to use its Google Maps APIs. It gives you $200/month of free usage before billing starts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query String Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A url that contains a query string will contain three parts:\n",
    "1. Resource (base) URL\n",
    "2. Question Mark (?)\n",
    "3. Parameters (key=value pairs) separated by an ampersand (&)\n",
    "\n",
    "Let's look at the Google geocoding example with our own API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://maps.googleapis.com/maps/api/geocode/json?address=915+E+Washington%2C+Ann+Arbor&key=AIzaSyAOuxKZ-stgmybcyKe4t46CPV2t3mOwSGE'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "apikey = 'AIzaSyAOuxKZ-stgmybcyKe4t46CPV2t3mOwSGE'\n",
    "url = f'https://maps.googleapis.com/maps/api/geocode/json?address=915+E+Washington%2C+Ann+Arbor&key={apikey}'\n",
    "url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break down the different pieces for this example.\n",
    "1. The resource url is `https://maps.googleapis.com/maps/api/geocode/json`\n",
    "2. The output format chosen was json\n",
    "3. `?`\n",
    "4. First required parameter is `address=1600+Amphitheatre+Parkway,+Mountain+View,+CA`\n",
    "5. `&`\n",
    "6. Second required parameter is `key=<YOUR API KEY>`\n",
    "7. No optional key/value pair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that some characters can not be part of the URL like spaces in the above example. Spaces are encoded as `+` or `%20`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now can make a `GET` request. Same as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'results': [{'address_components': [{'long_name': '915',\n",
       "     'short_name': '915',\n",
       "     'types': ['street_number']},\n",
       "    {'long_name': 'East Washington Street',\n",
       "     'short_name': 'E Washington St',\n",
       "     'types': ['route']},\n",
       "    {'long_name': 'Burns Park',\n",
       "     'short_name': 'Burns Park',\n",
       "     'types': ['neighborhood', 'political']},\n",
       "    {'long_name': 'Ann Arbor',\n",
       "     'short_name': 'Ann Arbor',\n",
       "     'types': ['locality', 'political']},\n",
       "    {'long_name': 'Washtenaw County',\n",
       "     'short_name': 'Washtenaw County',\n",
       "     'types': ['administrative_area_level_2', 'political']},\n",
       "    {'long_name': 'Michigan',\n",
       "     'short_name': 'MI',\n",
       "     'types': ['administrative_area_level_1', 'political']},\n",
       "    {'long_name': 'United States',\n",
       "     'short_name': 'US',\n",
       "     'types': ['country', 'political']},\n",
       "    {'long_name': '48109', 'short_name': '48109', 'types': ['postal_code']},\n",
       "    {'long_name': '1070',\n",
       "     'short_name': '1070',\n",
       "     'types': ['postal_code_suffix']}],\n",
       "   'formatted_address': '915 E Washington St, Ann Arbor, MI 48109, USA',\n",
       "   'geometry': {'location': {'lat': 42.2808083, 'lng': -83.7382583},\n",
       "    'location_type': 'ROOFTOP',\n",
       "    'viewport': {'northeast': {'lat': 42.2821572802915,\n",
       "      'lng': -83.73690931970849},\n",
       "     'southwest': {'lat': 42.2794593197085, 'lng': -83.7396072802915}}},\n",
       "   'place_id': 'ChIJG0N-sUGuPIgRhWJ5XDKXPt4',\n",
       "   'plus_code': {'compound_code': '77J6+8M Ann Arbor, Michigan, United States',\n",
       "    'global_code': '86JR77J6+8M'},\n",
       "   'types': ['street_address']}],\n",
       " 'status': 'OK'}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = requests.get(url)\n",
    "response = R.json()\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Webscraping done! API conquered!\n",
    "\n",
    "Manually encoding strings for URLs can be a pain. Thankfully, the `requests` library takes care of all this for us if we pass a dictionary to the `params` keyword argument.\n",
    "\n",
    "First we need to construct the dictionary for the parameters and the specify the resource url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'address': '915 E Washington, Ann Arbor',\n",
    "          'key':apikey\n",
    "         }\n",
    "baseurl = 'https://maps.googleapis.com/maps/api/geocode/json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a `GET` request with the params keyword argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'results': [{'address_components': [{'long_name': '915',\n",
       "     'short_name': '915',\n",
       "     'types': ['street_number']},\n",
       "    {'long_name': 'East Washington Street',\n",
       "     'short_name': 'E Washington St',\n",
       "     'types': ['route']},\n",
       "    {'long_name': 'Burns Park',\n",
       "     'short_name': 'Burns Park',\n",
       "     'types': ['neighborhood', 'political']},\n",
       "    {'long_name': 'Ann Arbor',\n",
       "     'short_name': 'Ann Arbor',\n",
       "     'types': ['locality', 'political']},\n",
       "    {'long_name': 'Washtenaw County',\n",
       "     'short_name': 'Washtenaw County',\n",
       "     'types': ['administrative_area_level_2', 'political']},\n",
       "    {'long_name': 'Michigan',\n",
       "     'short_name': 'MI',\n",
       "     'types': ['administrative_area_level_1', 'political']},\n",
       "    {'long_name': 'United States',\n",
       "     'short_name': 'US',\n",
       "     'types': ['country', 'political']},\n",
       "    {'long_name': '48109', 'short_name': '48109', 'types': ['postal_code']},\n",
       "    {'long_name': '1070',\n",
       "     'short_name': '1070',\n",
       "     'types': ['postal_code_suffix']}],\n",
       "   'formatted_address': '915 E Washington St, Ann Arbor, MI 48109, USA',\n",
       "   'geometry': {'location': {'lat': 42.2808083, 'lng': -83.7382583},\n",
       "    'location_type': 'ROOFTOP',\n",
       "    'viewport': {'northeast': {'lat': 42.2821572802915,\n",
       "      'lng': -83.73690931970849},\n",
       "     'southwest': {'lat': 42.2794593197085, 'lng': -83.7396072802915}}},\n",
       "   'place_id': 'ChIJG0N-sUGuPIgRhWJ5XDKXPt4',\n",
       "   'plus_code': {'compound_code': '77J6+8M Ann Arbor, Michigan, United States',\n",
       "    'global_code': '86JR77J6+8M'},\n",
       "   'types': ['street_address']}],\n",
       " 'status': 'OK'}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = requests.get(baseurl, params=params)\n",
    "R.raise_for_status()\n",
    "response = R.json()\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same result. And we can also spy the actual url that was sent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://maps.googleapis.com/maps/api/geocode/json?address=915+E+Washington%2C+Ann+Arbor&key=AIzaSyAOuxKZ-stgmybcyKe4t46CPV2t3mOwSGE'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R.url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! Pretty simple, eh! A lot of APIs work just like this. Some, of course, are a bit more complicated. \n",
    "\n",
    "**Note:** CSCAR occasionally runs workshops on using social media APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traversing a JSON object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that we have a JSON response from the API, we need to know how to parse it for the information we are looking for. A JSON object behaves like a Python dictionary in that it consists of key-value pairs. JSON objects consist of dictionaries and lists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To look at the variables in a JSON object hierarchically, use the `keys` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['results', 'status'])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access the key like you would a Python dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'address_components': [{'long_name': '915',\n",
       "    'short_name': '915',\n",
       "    'types': ['street_number']},\n",
       "   {'long_name': 'East Washington Street',\n",
       "    'short_name': 'E Washington St',\n",
       "    'types': ['route']},\n",
       "   {'long_name': 'Burns Park',\n",
       "    'short_name': 'Burns Park',\n",
       "    'types': ['neighborhood', 'political']},\n",
       "   {'long_name': 'Ann Arbor',\n",
       "    'short_name': 'Ann Arbor',\n",
       "    'types': ['locality', 'political']},\n",
       "   {'long_name': 'Washtenaw County',\n",
       "    'short_name': 'Washtenaw County',\n",
       "    'types': ['administrative_area_level_2', 'political']},\n",
       "   {'long_name': 'Michigan',\n",
       "    'short_name': 'MI',\n",
       "    'types': ['administrative_area_level_1', 'political']},\n",
       "   {'long_name': 'United States',\n",
       "    'short_name': 'US',\n",
       "    'types': ['country', 'political']},\n",
       "   {'long_name': '48109', 'short_name': '48109', 'types': ['postal_code']},\n",
       "   {'long_name': '1070',\n",
       "    'short_name': '1070',\n",
       "    'types': ['postal_code_suffix']}],\n",
       "  'formatted_address': '915 E Washington St, Ann Arbor, MI 48109, USA',\n",
       "  'geometry': {'location': {'lat': 42.2808083, 'lng': -83.7382583},\n",
       "   'location_type': 'ROOFTOP',\n",
       "   'viewport': {'northeast': {'lat': 42.2821572802915,\n",
       "     'lng': -83.73690931970849},\n",
       "    'southwest': {'lat': 42.2794593197085, 'lng': -83.7396072802915}}},\n",
       "  'place_id': 'ChIJG0N-sUGuPIgRhWJ5XDKXPt4',\n",
       "  'plus_code': {'compound_code': '77J6+8M Ann Arbor, Michigan, United States',\n",
       "   'global_code': '86JR77J6+8M'},\n",
       "  'types': ['street_address']}]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['results']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Occasionally, you will encounter a `list` of key-value pairs in the hierarchy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You would access the `list` the same way as a Python list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'address_components': [{'long_name': '915',\n",
       "   'short_name': '915',\n",
       "   'types': ['street_number']},\n",
       "  {'long_name': 'East Washington Street',\n",
       "   'short_name': 'E Washington St',\n",
       "   'types': ['route']},\n",
       "  {'long_name': 'Burns Park',\n",
       "   'short_name': 'Burns Park',\n",
       "   'types': ['neighborhood', 'political']},\n",
       "  {'long_name': 'Ann Arbor',\n",
       "   'short_name': 'Ann Arbor',\n",
       "   'types': ['locality', 'political']},\n",
       "  {'long_name': 'Washtenaw County',\n",
       "   'short_name': 'Washtenaw County',\n",
       "   'types': ['administrative_area_level_2', 'political']},\n",
       "  {'long_name': 'Michigan',\n",
       "   'short_name': 'MI',\n",
       "   'types': ['administrative_area_level_1', 'political']},\n",
       "  {'long_name': 'United States',\n",
       "   'short_name': 'US',\n",
       "   'types': ['country', 'political']},\n",
       "  {'long_name': '48109', 'short_name': '48109', 'types': ['postal_code']},\n",
       "  {'long_name': '1070',\n",
       "   'short_name': '1070',\n",
       "   'types': ['postal_code_suffix']}],\n",
       " 'formatted_address': '915 E Washington St, Ann Arbor, MI 48109, USA',\n",
       " 'geometry': {'location': {'lat': 42.2808083, 'lng': -83.7382583},\n",
       "  'location_type': 'ROOFTOP',\n",
       "  'viewport': {'northeast': {'lat': 42.2821572802915,\n",
       "    'lng': -83.73690931970849},\n",
       "   'southwest': {'lat': 42.2794593197085, 'lng': -83.7396072802915}}},\n",
       " 'place_id': 'ChIJG0N-sUGuPIgRhWJ5XDKXPt4',\n",
       " 'plus_code': {'compound_code': '77J6+8M Ann Arbor, Michigan, United States',\n",
       "  'global_code': '86JR77J6+8M'},\n",
       " 'types': ['street_address']}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['results'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, there is only one element in this list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to drill deeper into the `results` key, you would repeat the process to look at available keys and so forth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['address_components', 'formatted_address', 'geometry', 'place_id', 'plus_code', 'types'])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['results'][0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To arrive at the latitude coordinate, you would need the following syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.2808083"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['results'][0]['geometry']['location']['lat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: If you have a keen eye, you can just eyeball the hierarchy without needing to use the `keys` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 4: Weather Data (using an API)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of an API that doesn't follow the query string parameter format.\n",
    "\n",
    "We will be using <a href='https://darksky.net/app/'>https://darksky.net/app/</a> to gather weather data.  The developer section is at https://darksky.net/dev/. The API documentation is at https://darksky.net/dev/docs. You will need to create an account to get an API key (or you can borrow mine).\n",
    "\n",
    "**Note**: Dark Sky is a relatively simple API (part of the reason why I'm using it as an example). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather Forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "APIs usually have different endpoints depending on the data you are interested in. The documentation page shows that you can make two types of API requests. \n",
    "1. The current weather forecast for the next week (forecast request)\n",
    "2. An observed or forecast weather conditions for a date in the past or future (time machine request)\n",
    "\n",
    "**Note**: BTW, two is a relatively small number. The twitter API has over 100.\n",
    "\n",
    "Let's look at endpoint #2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The documentation shows that a forecast request takes the form of:\n",
    "\n",
    "https://api.darksky.net/forecast/[key]/[latitude],[longitude],[time]\n",
    "\n",
    "A historical weather request returns the observed weather at a given time (for many places, up to 60 years in the past)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by specifying the API key and then the GPS coordinates and timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "apikey = '69cdc2adbb82225c0d09eacbd8dab0a8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude = 42.28\n",
    "longitude = -83.74\n",
    "time = '2017-01-31T16:00:00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url = f'https://api.darksky.net/forecast/{apikey}/{latitude},{longitude},{time}'\n",
    "R = requests.get(url)\n",
    "R.raise_for_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API responses consist of a JSON-formatted object (UTF-8) according to the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pastforecast = R.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Webscraping DONE!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hourly summary and temperature for that day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Overcast 23.08\n",
      "1 Foggy 23.66\n",
      "2 Foggy 24.31\n",
      "3 Foggy 24.76\n",
      "4 Foggy 25.28\n",
      "5 Foggy 25.85\n",
      "6 Foggy 26.2\n",
      "7 Overcast 26.17\n",
      "8 Overcast 26.53\n",
      "9 Overcast 27.26\n",
      "10 Overcast 28.26\n",
      "11 Overcast 29.6\n",
      "12 Overcast 30.85\n",
      "13 Overcast 32.24\n",
      "14 Overcast 32.66\n",
      "15 Overcast 32.81\n",
      "16 Overcast 32.81\n",
      "17 Overcast 32.02\n",
      "18 Overcast 31.36\n",
      "19 Overcast 31.07\n",
      "20 Overcast 31.15\n",
      "21 Overcast 31.07\n",
      "22 Mostly Cloudy 31.32\n",
      "23 Partly Cloudy 31.36\n"
     ]
    }
   ],
   "source": [
    "for i, hr in enumerate(pastforecast[\"hourly\"][\"data\"]):\n",
    "    print(i, hr['summary'], hr['temperature'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: API responses come in a variety of flavours. Some common ones are JSON, XML, and CSV format. I recommend choosing JSON over XML whenever possible. XML is a pain to work with IMO. If you do choose XML, you can use `BeautifulSoup` or `ElementTree` to parse the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Wrappers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the more popular APIs (like Twitter and Google), the open source community has probably written a Python wrapper for the API to abstract away some of the details for you. The Dark Sky API is pretty simple as you can see but someone has written a wrapper for it because of its popularity. The Python module is called `python-forecastio`. You can install it using `pip install python-forecastio`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import forecastio\n",
    "\n",
    "lon = -83.7\n",
    "lat = 42.3\n",
    "forecast = forecastio.load_forecast(apikey, lat, lon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing the data depends on the structure the developer set up which is not necessarily the same as the API. You will need to read the documentation of the module to understand the structure or figure it out by trial and error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2018-11-16 16:00:00 Overcast 30.87\n",
      "1 2018-11-16 17:00:00 Overcast 31.64\n",
      "2 2018-11-16 18:00:00 Overcast 32.61\n",
      "3 2018-11-16 19:00:00 Overcast 34\n",
      "4 2018-11-16 20:00:00 Overcast 35.92\n",
      "5 2018-11-16 21:00:00 Overcast 37.17\n",
      "6 2018-11-16 22:00:00 Overcast 37.09\n",
      "7 2018-11-16 23:00:00 Overcast 36.76\n",
      "8 2018-11-17 00:00:00 Overcast 35.99\n",
      "9 2018-11-17 01:00:00 Mostly Cloudy 35.29\n",
      "10 2018-11-17 02:00:00 Mostly Cloudy 34.35\n",
      "11 2018-11-17 03:00:00 Mostly Cloudy 33.84\n",
      "12 2018-11-17 04:00:00 Mostly Cloudy 33.52\n",
      "13 2018-11-17 05:00:00 Mostly Cloudy 33.62\n",
      "14 2018-11-17 06:00:00 Mostly Cloudy 33.73\n",
      "15 2018-11-17 07:00:00 Mostly Cloudy 33.29\n",
      "16 2018-11-17 08:00:00 Mostly Cloudy 33.25\n",
      "17 2018-11-17 09:00:00 Overcast 33.02\n",
      "18 2018-11-17 10:00:00 Overcast 32.2\n",
      "19 2018-11-17 11:00:00 Overcast 31.28\n",
      "20 2018-11-17 12:00:00 Overcast 30.77\n",
      "21 2018-11-17 13:00:00 Overcast 30.86\n",
      "22 2018-11-17 14:00:00 Overcast 31.56\n",
      "23 2018-11-17 15:00:00 Overcast 32.53\n",
      "24 2018-11-17 16:00:00 Overcast 33.39\n",
      "25 2018-11-17 17:00:00 Overcast 34.26\n",
      "26 2018-11-17 18:00:00 Light Snow 34.98\n",
      "27 2018-11-17 19:00:00 Light Snow 35.14\n",
      "28 2018-11-17 20:00:00 Snow 35.13\n",
      "29 2018-11-17 21:00:00 Snow 34.42\n",
      "30 2018-11-17 22:00:00 Light Snow 33.47\n",
      "31 2018-11-17 23:00:00 Overcast 32.42\n",
      "32 2018-11-18 00:00:00 Overcast 31.79\n",
      "33 2018-11-18 01:00:00 Overcast 31.11\n",
      "34 2018-11-18 02:00:00 Overcast 30.43\n",
      "35 2018-11-18 03:00:00 Overcast 29.72\n",
      "36 2018-11-18 04:00:00 Overcast 28.86\n",
      "37 2018-11-18 05:00:00 Overcast 28.03\n",
      "38 2018-11-18 06:00:00 Overcast 27.46\n",
      "39 2018-11-18 07:00:00 Overcast 27.11\n",
      "40 2018-11-18 08:00:00 Overcast 27.07\n",
      "41 2018-11-18 09:00:00 Overcast 26.55\n",
      "42 2018-11-18 10:00:00 Mostly Cloudy 25.71\n",
      "43 2018-11-18 11:00:00 Mostly Cloudy 24.92\n",
      "44 2018-11-18 12:00:00 Mostly Cloudy 24.87\n",
      "45 2018-11-18 13:00:00 Mostly Cloudy 25.37\n",
      "46 2018-11-18 14:00:00 Mostly Cloudy 26.49\n",
      "47 2018-11-18 15:00:00 Mostly Cloudy 27.96\n",
      "48 2018-11-18 16:00:00 Mostly Cloudy 29.95\n"
     ]
    }
   ],
   "source": [
    "for i, hr in enumerate(forecast.hourly().data):\n",
    "    print(i, hr.time, hr.summary, hr.temperature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Google Maps Distance Matrix API, get the the distance from Ann Arbor, MI to San Diego, CA and Anchorage, AK.\n",
    "\n",
    "The documentation is located at https://developers.google.com/maps/documentation/distance-matrix/start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: POST Requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example was taken from the book **Web Scraping with Python** by Ryan Mitchell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This website http://pythonscraping.com/pages/files/form.html shows a basic web form. Let's look at the page source to see info related to the `post` request."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The page source contains the variable names of the two input fields which need to be submitted in the `<form>` tag. We create a dictionary to represent these fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'firstname':'Mister',\n",
    "        'lastname' :'Cao'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an `action` attribute associated with the `post` request. This is the url where the `post` is being sent. This is a **relative** path to the current url. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello there, Mister Cao!'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = requests.post(\"http://pythonscraping.com/pages/files/processing.php\", data=data)\n",
    "R.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll see in the next section a way to get at the same information through the browser's developer tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 6: Farm Equipment Crashes in Ann Arbor (data that is not visible in the page source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example is meant to illustrate how to grab data that is visible on the webpage but not in the page source. The website of interest is https://www.michigantrafficcrashfacts.org/querytool. We are interested in grabbing the gps coordinates of the crashes on the map. The crashes also has some information in a popup tooltip when you click on it.\n",
    "\n",
    "The goal is to find the URL where the GET/POST request is being sent. How do we do that? The answer lies in the reference link at the bottom of this example. Basically, you need your browser's developer tool and some detective work.  \n",
    "[SHORT OVERLUDE TO THE WEBPAGE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congrats! You can consider yourself a developer now that you can use the toolbox :)\n",
    "\n",
    "Now that we have found the URL of interest, we go back to our regularly scheduled programming (pun intended). Everything should be easy peasy moving forward. We know the url where the `post` request is being sent. There is also some data being sent with it. We will create a dictionary for that bit of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcf_url = r'https://www.michigantrafficcrashfacts.org/qjson'\n",
    "query = {'q':'1;0;2017,2016,2015,2014,2013,2012,2011,2010,2009,2008;c8189;0,42:1',\n",
    "        'v':'map',\n",
    "        'p':'13,42.264652,-83.729607,0.3'}   \n",
    "R = requests.post(mtcf_url, data=query)\n",
    "R.raise_for_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab json response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'warnings': [],\n",
       " 'errors': [],\n",
       " 'meta': [],\n",
       " 'headers': {'crash.id': 'Crash ID',\n",
       "  'crash_day': 'Crash Day',\n",
       "  'crash_month': 'Crash Month',\n",
       "  'crash_year': 'Crash Year',\n",
       "  'crash_time_of_day': 'Crash Hour',\n",
       "  'crash_worst_injury': 'Crash Worst Injury',\n",
       "  'gps_x_coordinate': 'Crash Lat',\n",
       "  'gps_y_coordinate': 'Crash Long',\n",
       "  'seg_crnt': 'Road Segment',\n",
       "  'seg_orig': 'Orig Segment',\n",
       "  'vehicle_id': 'Unit Count',\n",
       "  'person_id': 'Person Count'},\n",
       " '0': {'crash.id': '2015113037',\n",
       "  'crash_day': 26,\n",
       "  'crash_month': 'February',\n",
       "  'crash_year': '2015',\n",
       "  'crash_time_of_day': '8:00 AM - 9:00 AM',\n",
       "  'crash_worst_injury': 'No injury (O)',\n",
       "  'gps_x_coordinate': -83.78405039994,\n",
       "  'gps_y_coordinate': 42.281289282301,\n",
       "  'seg_crnt': 4818100,\n",
       "  'seg_orig': 0,\n",
       "  'vehicle_id': '2',\n",
       "  'person_id': '2'},\n",
       " '1': {'crash.id': '2011112810',\n",
       "  'crash_day': 23,\n",
       "  'crash_month': 'May',\n",
       "  'crash_year': '2011',\n",
       "  'crash_time_of_day': '7:00 AM - 8:00 AM',\n",
       "  'crash_worst_injury': 'No injury (O)',\n",
       "  'gps_x_coordinate': -83.720369104399,\n",
       "  'gps_y_coordinate': 42.261075358399,\n",
       "  'seg_crnt': 4827523,\n",
       "  'seg_orig': 0,\n",
       "  'vehicle_id': '2',\n",
       "  'person_id': '2'},\n",
       " '2': {'crash.id': '2015156119',\n",
       "  'crash_day': 14,\n",
       "  'crash_month': 'July',\n",
       "  'crash_year': '2015',\n",
       "  'crash_time_of_day': '5:00 PM - 6:00 PM',\n",
       "  'crash_worst_injury': 'Possible injury (C)',\n",
       "  'gps_x_coordinate': -83.762084436151,\n",
       "  'gps_y_coordinate': 42.2444715503,\n",
       "  'seg_crnt': 10003762,\n",
       "  'seg_orig': 0,\n",
       "  'vehicle_id': '3',\n",
       "  'person_id': '8'}}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crash_data = R.json()\n",
    "crash_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Webscraping DONE!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "http://www.gregreda.com/2015/02/15/web-scraping-finding-the-api/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This website generates random VINs upon demand http://randomvin.com. This is probably one of the most simplest html page you will ever see (and one of the reasons I picked it)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is some example code to grab 3 VINs from the website. Supply the appropriate url to finish the code. What file format is the response?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    R = requests.get('')\n",
    "    R.raise_for_status()\n",
    "    print(R.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrying Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module is aptly name. Even though you have written valid code, sometimes it will still crash for unforseen reasons (e.g. bad network connection). This is where the `retry` behaviour becomes handy. You will need to install the module first via `pip install retrying`. Documentation is at https://pypi.python.org/pypi/retrying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from retrying import retry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Retry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a simple case of how to use `retry`. First step is to put your code of interest in a function. This non-sensical function has a 90% chance of failing when run because of the `assert` statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-b7b5add69536>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0mB\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mis_B_equal_to_lucky7\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'this has a 10% chance of printing'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-b7b5add69536>\u001b[0m in \u001b[0;36mis_B_equal_to_lucky7\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32massert\u001b[0m \u001b[0mB\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mis_B_equal_to_lucky7\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def is_B_equal_to_lucky7():\n",
    "    B = random.randint(1, 10)\n",
    "    print(B)\n",
    "    assert B == 7\n",
    "\n",
    "is_B_equal_to_lucky7()\n",
    "print('this has a 10% chance of printing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add the `retry` behavior by adding an @ decorator at the beginning of the function. That's it! Pretty simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "1\n",
      "10\n",
      "6\n",
      "9\n",
      "6\n",
      "7\n",
      "this will ALWAYS print\n"
     ]
    }
   ],
   "source": [
    "@retry()\n",
    "def is_B_equal_to_lucky7():\n",
    "    B = random.randint(1, 10)\n",
    "    print(B)\n",
    "    assert B == 7\n",
    "    \n",
    "is_B_equal_to_lucky7()\n",
    "print('this will ALWAYS print')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also add an argument `wait_fixed` in milliseconds to specify how long to wait between retries. Good practice so you don't have to bombard the server with constant requests during a failed connection during webscraping. Gmail does an exponential version of this when it loses the network connection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retry on specific or general exceptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw the function fail earlier because of an `AssertionError`. We can tell `retry` to only retry when certain exceptions occur.  This requires using the argument `retry_on_exception` and passing it the name of a function. The function will return either `True` or `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "7\n",
      "Lucky 7\n"
     ]
    }
   ],
   "source": [
    "def checkForSpecificError(exception):\n",
    "    return isinstance(exception, AssertionError)\n",
    "\n",
    "@retry(retry_on_exception=checkForSpecificError, wait_fixed=500)\n",
    "def is_it_lucky7():\n",
    "    B = random.randint(1, 10)\n",
    "    print(B)\n",
    "    assert B == 7\n",
    "\n",
    "is_it_lucky7()\n",
    "print(\"Lucky 7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we had changed the last line in the function to `assert C == 7`, then the retry behaviour will not kick in because the function returns a `NameError`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retry on return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You don't necessarily need to have a program error to invoke the `retry` behaviour. You can use the `return` value to decide. This requires using the argument `retry_on_result` and passing it the name of a function. The function will return either `True` or `False`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2\n",
      "8\n",
      "7\n",
      "Did I find a 7?\n"
     ]
    }
   ],
   "source": [
    "def checkReturnValue(value):\n",
    "    return value is True\n",
    "\n",
    "# This function will never crash but we can still use retry\n",
    "@retry(retry_on_result=checkReturnValue, wait_fixed=300)\n",
    "def main():\n",
    "    B = random.randint(1, 10)\n",
    "    print(B)\n",
    "    try:\n",
    "        assert B == 7\n",
    "        return None\n",
    "    except AssertionError:\n",
    "        return True\n",
    "\n",
    "main()\n",
    "print('Did I find a 7?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other arguments of interest to `retry` which you can use are:  \n",
    "- stop_max_attempt_number\n",
    "- stop_max_delay\n",
    "- wait_random_min\n",
    "- wait_random_max\n",
    "- wait_exponential_multiplier\n",
    "- wait_exponential_max`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: You could implement the retry behavior without this module. You can use a `while` loop in some combination with `try` and `except` too. I don't recommend it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the `retry` module to this flaky code for the Dark Sky API to try 5 times waiting one second in between attempts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather_from_Eastern_hemisphere(apikey):\n",
    "    lon = random.randint(0,400)\n",
    "    lat = random.randint(0,200)\n",
    "    print('{} deg E, {} deg N'.format(lon,lat))\n",
    "    R = requests.get('https://api.darksky.net/forecast/{}/{},{}'.format(apikey,lat,lon))\n",
    "    R.raise_for_status()\n",
    "    return (lon,lat,R.json())\n",
    "    \n",
    "apikey = '69cdc2adbb82225c0d09eacbd8dab0a8'\n",
    "lon, lat, forecast = get_weather_from_Eastern_hemisphere(apikey)\n",
    "print(forecast[\"daily\"][\"data\"][0]['summary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://goo.gl/forms/Ym3hbKu45nzQ2puv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cURL to Python Requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cURL is a command line tool for getting or sending files using URL syntax. You can always get the cURL command from the developer tool. This usually also includes *cookies and headers*. While Python can't use it directly, you can convert it to a Python requests syntax. Googling *curl to python requests* will bring you to this page https://curl.trillworks.com/. You can paste the curl code and it will return the equivalent Python code for you. Python does have a module that is suppose to do this for you but I haven't gotten it to work yet. Some modules are `uncurl, runcurl, curl_to_requests` but they support Python2 only.\n",
    "\n",
    "For example, here is what is returned for the curl cmd from http://random.vin.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "cookies = {\n",
    "    '_ga': 'GA1.2.690271399.1483585728',\n",
    "    '_gat': '1',\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    'Accept-Encoding': 'gzip, deflate, sdch',\n",
    "    'Accept-Language': 'en-US,en;q=0.8',\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36',\n",
    "    'Accept': '*/*',\n",
    "    'Referer': 'http://randomvin.com/',\n",
    "    'Connection': 'keep-alive',\n",
    "}\n",
    "\n",
    "requests.get('http://randomvin.com/getvin.php?type=real', headers=headers, cookies=cookies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robots.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also known as the robot exclusion standard, *robots.txt* is a standard used by website to communicate to web crawlers, scrapers etc. The robots.txt is a file that is used to communicate which parts of the website is allowed or disallowed to be scraped. You will find the robots.txt file in the root directory of the website. For the english version of wikipedia, it is located at https://en.wikipedia.org/robots.txt.  \n",
    "\n",
    "The complement to *robots.txt* is the *sitemap* which is an XML file that lists the URLs for a site. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
